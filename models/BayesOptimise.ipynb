{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import os, json\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV, Optimizer\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentedv3\n",
      "no FSv2\n",
      "no SNV standardisation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = OrderedDict([('max_depth', 4), ('max_features', None)]) \n",
      "best_score: 0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 473\u001b[0m\n\u001b[0;32m    468\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m    469\u001b[0m     \u001b[39m# use log-uniform for quicker convergence (Lewinson, 2022)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvar_smoothing\u001b[39m\u001b[39m'\u001b[39m:Real(\u001b[39m1e-20\u001b[39m, \u001b[39m0.1\u001b[39m, prior\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog-uniform\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# from less smoothing to more aggressive smoothing\u001b[39;00m\n\u001b[0;32m    471\u001b[0m }\n\u001b[0;32m    472\u001b[0m bayes_search \u001b[39m=\u001b[39m BayesSearchCV(clf_nb, params, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 473\u001b[0m _ \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39;49mfit(training_data, np\u001b[39m.\u001b[39;49mravel(training_labels))\n\u001b[0;32m    474\u001b[0m best_params \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m    475\u001b[0m best_score \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, groups\u001b[39m=\u001b[39mgroups, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[0;32m    513\u001b[0m         search_space, optimizer,\n\u001b[0;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[39m=\u001b[39;49mn_points_adjusted\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\searchcv.py:412\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[39m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[0;32m    411\u001b[0m local_results \u001b[39m=\u001b[39m all_results[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(params):]\n\u001b[1;32m--> 412\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mtell(params, [\u001b[39m-\u001b[39;49mscore \u001b[39mfor\u001b[39;49;00m score \u001b[39min\u001b[39;49;00m local_results])\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.tell\u001b[1;34m(self, x, y, fit)\u001b[0m\n\u001b[0;32m    490\u001b[0m         y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(y)\n\u001b[0;32m    491\u001b[0m         y[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m log(y[\u001b[39m1\u001b[39m])\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tell(x, y, fit\u001b[39m=\u001b[39;49mfit)\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:557\u001b[0m, in \u001b[0;36mOptimizer._tell\u001b[1;34m(self, x, y, fit)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_xs_ \u001b[39m=\u001b[39m []\n\u001b[0;32m    556\u001b[0m \u001b[39mfor\u001b[39;00m cand_acq_func \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcand_acq_funcs_:\n\u001b[1;32m--> 557\u001b[0m     values \u001b[39m=\u001b[39m _gaussian_acquisition(\n\u001b[0;32m    558\u001b[0m         X\u001b[39m=\u001b[39;49mX, model\u001b[39m=\u001b[39;49mest, y_opt\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mmin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49myi),\n\u001b[0;32m    559\u001b[0m         acq_func\u001b[39m=\u001b[39;49mcand_acq_func,\n\u001b[0;32m    560\u001b[0m         acq_func_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49macq_func_kwargs)\n\u001b[0;32m    561\u001b[0m     \u001b[39m# Find the minimum of the acquisition function by randomly\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[39m# sampling points from the space\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macq_optimizer \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msampling\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\acquisition.py:53\u001b[0m, in \u001b[0;36m_gaussian_acquisition\u001b[1;34m(X, model, y_opt, acq_func, return_grad, acq_func_kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     func_and_grad \u001b[39m=\u001b[39m gaussian_ei(X, model, y_opt, xi, return_grad)\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     func_and_grad \u001b[39m=\u001b[39m gaussian_pi(X, model, y_opt, xi, return_grad)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m return_grad:\n\u001b[0;32m     56\u001b[0m     acq_vals \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mfunc_and_grad[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\acquisition.py:202\u001b[0m, in \u001b[0;36mgaussian_pi\u001b[1;34m(X, model, y_opt, xi, return_grad)\u001b[0m\n\u001b[0;32m    198\u001b[0m         mu, std, mu_grad, std_grad \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m    199\u001b[0m             X, return_std\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_mean_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m             return_std_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    201\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m         mu, std \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X, return_std\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    204\u001b[0m \u001b[39m# check dimensionality of mu, std so we can divide them below\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mif\u001b[39;00m (mu\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m (std\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\learning\\gaussian_process\\gpr.py:332\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.predict\u001b[1;34m(self, X, return_std, return_cov, return_mean_grad, return_std_grad)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m# Compute variance of predictive distribution\u001b[39;00m\n\u001b[0;32m    331\u001b[0m y_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_\u001b[39m.\u001b[39mdiag(X)\n\u001b[1;32m--> 332\u001b[0m y_var \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meinsum(\u001b[39m\"\u001b[39;49m\u001b[39mki,kj,ij->k\u001b[39;49m\u001b[39m\"\u001b[39;49m, K_trans, K_trans, K_inv)\n\u001b[0;32m    334\u001b[0m \u001b[39m# Check if any of the variances is negative because of\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[39m# numerical issues. If yes: set the variance to 0.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m y_var_negative \u001b[39m=\u001b[39m y_var \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\numpy\\core\\einsumfunc.py:1361\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[39mif\u001b[39;00m specified_out:\n\u001b[0;32m   1360\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out\n\u001b[1;32m-> 1361\u001b[0m     \u001b[39mreturn\u001b[39;00m c_einsum(\u001b[39m*\u001b[39moperands, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1363\u001b[0m \u001b[39m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[39m# repeat default values here\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m valid_einsum_kwargs \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcasting\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for experiment in experiments, set pipeline flags and run bayesian optimisation on each model\n",
    "# record results in new scoreboard - are there any improvements?\n",
    "# if yes, use these models for ensemble, otherwise use gridsearch acquired models for ensemble\n",
    "\n",
    "# to dynamically toggle flags for each experiment\n",
    "\n",
    "experiments = {'svmsmote':{'SVMSMOTE':True},\n",
    "               'augmented_FS':{'AUGMENTED':True, 'FEATURE_SELECT':True},\n",
    "               'snv_FS_balanced':{'SNV':True, 'FEATURE_SELECT':True, 'BALANCED':True}, \n",
    "               'snv_FS_svmsmote':{'SNV':True, 'SVMSMOTE':True, 'FEATURE_SELECT':True}, \n",
    "               'snv_svmsmote':{'SNV':True, 'SVMSMOTE':True}, \n",
    "               'kmeanssmote':{'KMEANSSMOTE':True}, \n",
    "               'augmentedv3_FS':{'AUGMENTEDv3':True, 'FEATURE_SELECT':True}, \n",
    "               'bordersmote':{'BORDERSMOTE':True}, \n",
    "               'snv_augmentedv3':{'SNV':True, 'AUGMENTEDv3':True}, \n",
    "               'augmentedv3':{'AUGMENTEDv3':True}, \n",
    "               'adasynsmote':{'ADASYNSMOTE':True}, \n",
    "               'smote':{'SMOTE':True}, \n",
    "               'raw':{}}\n",
    "\n",
    "for experiment in experiments:\n",
    "    SNV = False\n",
    "    FEATURE_SELECT = False\n",
    "    FEATURE_SELECTv2 = False\n",
    "    BALANCED = False\n",
    "    MY_BALANCED = False\n",
    "    MY_BALANCEDv2 = False\n",
    "    AUGMENTED = False # oversampling of neoplasia\n",
    "    AUGMENTEDv2 = False # actual augmented\n",
    "    AUGMENTEDv3 = False # augmented neoplasia only\n",
    "    SMOTE = False\n",
    "    SVMSMOTE = False\n",
    "    KMEANSSMOTE = False\n",
    "    ADASYNSMOTE = False\n",
    "    BORDERSMOTE = False\n",
    "    \n",
    "    # set flags\n",
    "    try:\n",
    "        SNV = experiments[experiment]['SNV']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'SNV not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        FEATURE_SELECT = experiments[experiment]['FEATURE_SELECT']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'FEATURE_SELECT not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        FEATURE_SELECTv2 = experiments[experiment]['FEATURE_SELECTv2']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'FEATURE_SELECTv2 not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        BALANCED = experiments[experiment]['BALANCED']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'BALANCED not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        AUGMENTED = experiments[experiment]['AUGMENTED']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'AUGMENTED not in {experiment}')\n",
    "    \n",
    "    try:\n",
    "        MY_BALANCEDv2 = experiments[experiment]['MY_BALANCEDv2']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'MY_BALANCEDv2 not in {experiment}')\n",
    "    \n",
    "    try:\n",
    "        AUGMENTEDv2 = experiments[experiment]['AUGMENTEDv2']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'AUGMENTEDv2 not in {experiment}')\n",
    "    \n",
    "    try:\n",
    "        AUGMENTEDv3 = experiments[experiment]['AUGMENTEDv3']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'AUGMENTEDv3 not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        SMOTE = experiments[experiment]['SMOTE']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'SMOTE not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        SVMSMOTE = experiments[experiment]['SVMSMOTE']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'SVMSMOTE not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        KMEANSSMOTE = experiments[experiment]['KMEANSSMOTE']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'KMEANSSMOTE not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        ADASYNSMOTE = experiments[experiment]['ADASYNSMOTE']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'ADASYNSMOTE not in {experiment}')\n",
    "\n",
    "    try:\n",
    "        BORDERSMOTE = experiments[experiment]['BORDERSMOTE']\n",
    "    except:\n",
    "        pass\n",
    "        # print(f'BORDERSMOTE not in {experiment}')\n",
    "\n",
    "    # Choose dataset\n",
    "    DATASET = 'raw'\n",
    "    FILENAME_ACC = 'BOmetrics/raw_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'BOmetrics/raw_dataset/model_metrics_recall_ensemble.json'\n",
    "\n",
    "    if BALANCED:\n",
    "        DATASET = 'balanced'\n",
    "        FILENAME_ACC = 'BOmetrics/balanced_dataset/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/balanced_dataset/model_metrics_recall_ensemble.json'\n",
    "        if SNV:\n",
    "            DATASET = 'snv_balanced'\n",
    "            FILENAME_ACC = 'BOmetrics/balanced_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/balanced_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "            if FEATURE_SELECT:\n",
    "                DATASET = 'snv_FS_balanced'\n",
    "                FILENAME_ACC = 'BOmetrics/balanced_dataset/model_metrics_accuracy_ensemble_snv_FS.json'\n",
    "                FILENAME_RECALL = 'BOmetrics/balanced_dataset/model_metrics_recall_ensemble_snv_FS.json'\n",
    "    elif MY_BALANCED:\n",
    "        DATASET = 'my_balanced'\n",
    "        FILENAME_ACC = 'BOmetrics/my_balanced_dataset/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/my_balanced_dataset/model_metrics_recall_ensemble.json'\n",
    "        if FEATURE_SELECT:\n",
    "            DATASET = 'FS_my_balanced'\n",
    "            FILENAME_ACC = 'BOmetrics/my_balanced_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/my_balanced_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "            if SNV:\n",
    "                DATASET = 'snv_FS_my_balanced'\n",
    "                FILENAME_ACC = 'BOmetrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv_FS.json'\n",
    "                FILENAME_RECALL = 'BOmetrics/my_balanced_dataset/model_metrics_recall_ensemble_snv_FS.json'\n",
    "        elif FEATURE_SELECTv2:\n",
    "            DATASET = 'FSv2_my_balanced'\n",
    "            FILENAME_ACC = 'BOmetrics/my_balanced_dataset/model_metrics_accuracy_ensemble_FSv2.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/my_balanced_dataset/model_metrics_recall_ensemble_FSv2.json'\n",
    "        elif SNV:\n",
    "            DATASET = 'snv_my_balanced'\n",
    "            FILENAME_ACC = 'BOmetrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/my_balanced_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "    elif AUGMENTED:\n",
    "        DATASET = 'augmented'\n",
    "        FILENAME_ACC = 'BOmetrics/augmented_dataset/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/augmented_dataset/model_metrics_recall_ensemble.json'\n",
    "        if FEATURE_SELECT:\n",
    "            DATASET = 'augmented_FS'\n",
    "            FILENAME_ACC = 'BOmetrics/augmented_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/augmented_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "    elif AUGMENTEDv2:\n",
    "        DATASET = 'augmentedv2'\n",
    "        FILENAME_ACC = 'BOmetrics/augmentedv2_dataset/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/augmentedv2_dataset/model_metrics_recall_ensemble.json'\n",
    "        if FEATURE_SELECT:\n",
    "            DATASET = 'augmentedv2_FS'\n",
    "            FILENAME_ACC = 'BOmetrics/augmentedv2_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/augmentedv2_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "    elif AUGMENTEDv3:\n",
    "        DATASET = 'augmentedv3'\n",
    "        FILENAME_ACC = 'BOmetrics/augmentedv3_dataset/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/augmentedv3_dataset/model_metrics_recall_ensemble.json'\n",
    "        if SNV:\n",
    "            DATASET = 'snv_augmentedv3'\n",
    "            FILENAME_ACC = 'BOmetrics/augmentedv3_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/augmentedv3_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "        if FEATURE_SELECT:\n",
    "            DATASET = 'augmentedv3_FS'\n",
    "            FILENAME_ACC = 'BOmetrics/augmentedv3_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/augmentedv3_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "    elif SMOTE:\n",
    "        DATASET = 'smote'\n",
    "        FILENAME_ACC = 'BOmetrics/smote/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/smote/model_metrics_recall_ensemble.json'\n",
    "    elif SVMSMOTE:\n",
    "        DATASET = 'svmsmote'\n",
    "        FILENAME_ACC = 'BOmetrics/svmsmote/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/svmsmote/model_metrics_recall_ensemble.json'\n",
    "        if FEATURE_SELECT:\n",
    "            DATASET = 'FS_svmsmote'\n",
    "            FILENAME_ACC = 'BOmetrics/svmsmote/model_metrics_accuracy_ensemble_FS.json'\n",
    "            FILENAME_RECALL = 'BOmetrics/svmsmote/model_metrics_recall_ensemble_FS.json'\n",
    "            if SNV:\n",
    "                DATASET = 'snv_FS_svmsmote'\n",
    "                FILENAME_ACC = 'BOmetrics/svmsmote/model_metrics_accuracy_ensemble_snv_FS.json'\n",
    "                FILENAME_RECALL = 'BOmetrics/svmsmote/model_metrics_recall_ensemble_snv_FS.json'\n",
    "        if SNV:\n",
    "                DATASET = 'snv_svmsmote'\n",
    "                FILENAME_ACC = 'BOmetrics/svmsmote/model_metrics_accuracy_ensemble_FS.json'\n",
    "                FILENAME_RECALL = 'BOmetrics/svmsmote/model_metrics_recall_ensemble_FS.json'\n",
    "    elif KMEANSSMOTE:\n",
    "        DATASET = 'kmeanssmote'\n",
    "        FILENAME_ACC = 'BOmetrics/kmeanssmote/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/kmeanssmote/model_metrics_recall_ensemble.json'\n",
    "    elif ADASYNSMOTE:\n",
    "        DATASET = 'adasynsmote'\n",
    "        FILENAME_ACC = 'BOmetrics/adasynsmote/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/adasynsmote/model_metrics_recall_ensemble.json'\n",
    "    elif BORDERSMOTE:\n",
    "        DATASET = 'bordersmote'\n",
    "        FILENAME_ACC = 'BOmetrics/bordersmote/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/bordersmote/model_metrics_recall_ensemble.json'\n",
    "    elif MY_BALANCEDv2:\n",
    "        DATASET = 'my_balancedv2'\n",
    "        FILENAME_ACC = 'BOmetrics/my_balancedv2_dataset/model_metrics_accuracy_ensemble.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/my_balancedv2_dataset/model_metrics_recall_ensemble.json'\n",
    "    elif SNV:\n",
    "        DATASET = 'snv_raw'\n",
    "        FILENAME_ACC = 'BOmetrics/raw_dataset/model_metrics_accuracy_snv.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/raw_dataset/model_metrics_recall_snv.json'\n",
    "    elif FEATURE_SELECT:\n",
    "        DATASET = 'feature_select'\n",
    "        FILENAME_ACC = 'BOmetrics/selected_features/model_metrics_accuracy.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/selected_features/model_metrics_recall.json'\n",
    "    elif FEATURE_SELECTv2:\n",
    "        DATASET = 'feature_selectv2'\n",
    "        FILENAME_ACC = 'BOmetrics/selected_features/model_metrics_accuracy2.json'\n",
    "        FILENAME_RECALL = 'BOmetrics/selected_features/model_metrics_recall2.json'\n",
    "\n",
    "    # choose dataset and set x_train, x_test, y_train, y_test\n",
    "    if MY_BALANCED:\n",
    "        print('my_balanced')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/balanced_data/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/balanced_data/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/balanced_data/test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/balanced_data/test_label.csv', header = None)\n",
    "    elif BALANCED:\n",
    "        print('balanced')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/original_data/balanced_train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/original_data/balanced_train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/balanced_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/balanced_test_label.csv', header = None)\n",
    "    elif AUGMENTED:\n",
    "        print('augmented')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/augmented_data/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/augmented_data/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif AUGMENTEDv2:\n",
    "        print('augmentedv2')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/augmented_datav2/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/augmented_datav2/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif AUGMENTEDv3:\n",
    "        print('augmentedv3')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/augmented_datav3/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/augmented_datav3/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif MY_BALANCEDv2:\n",
    "        print('my_balancedv2')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/balancedv2_data/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/balancedv2_data/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif SMOTE:\n",
    "        print('smote')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/SMOTE/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/SMOTE/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif SVMSMOTE:\n",
    "        print('svmsmote')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/SMOTE/svm/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/SMOTE/svm/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif KMEANSSMOTE:\n",
    "        print('kmeanssmote')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/SMOTE/kmeans/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/SMOTE/kmeans/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif ADASYNSMOTE:\n",
    "        print('adasynsmote')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/SMOTE/adasyn/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/SMOTE/adasyn/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    elif BORDERSMOTE:\n",
    "        print('bordersmote')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/SMOTE/border/train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/SMOTE/border/train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "    else:\n",
    "        print('raw')\n",
    "        # x_train\n",
    "        training_data = pd.read_csv('../data/original_data/noExclusion_train_data.csv', header = None)\n",
    "        # y_train\n",
    "        training_labels = pd.read_csv('../data/original_data/noExclusion_train_label.csv', header = None)\n",
    "        # x_test\n",
    "        testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "        # y_test\n",
    "        testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "\n",
    "    # print(f\"training labels vc: \\n{training_labels.value_counts()}, \\ntesting labels vc: \\n{testing_labels.value_counts()}\")\n",
    "    # print(len(training_data), len(training_labels), len(testing_data), len(testing_labels))\n",
    "\n",
    "    # type cast labels to ints\n",
    "    training_labels[0] = training_labels[0].astype(int)\n",
    "    # testing_labels\n",
    "    testing_labels[0] = testing_labels[0].astype(int)\n",
    "\n",
    "    # encode labels, using sklearn, to pass to xgboost\n",
    "    # this code was inspired by the snippet from:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "    le = LabelEncoder()\n",
    "    # fit the classes to the encoder and transform labels to be 0,1,2\n",
    "    training_labels = le.fit_transform(training_labels[0].to_list())\n",
    "    testing_labels = le.fit_transform(testing_labels[0].to_list())\n",
    "\n",
    "    # bayessearch results\n",
    "    gs_results = {DATASET:{}}\n",
    "    # print(np.unique(training_labels))\n",
    "\n",
    "    # FEATURE SELECT\n",
    "    # RUN THIS TO APPLY FEATURE SELECTION TO TRAINING DATA\n",
    "    if FEATURE_SELECT == True:\n",
    "        ADD_POSSIBLE_FIGURES = True\n",
    "\n",
    "        # figures contain features from (figure_num*4)+1 \n",
    "        selected_figures = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                            21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\n",
    "                            39,40,41,42,43,44,45,46,47,48,49,50,51,52]\n",
    "\n",
    "        # figures that MAY be decent - noisy but different peaks\n",
    "        possible_figures = [53,54,56,57,58,59,60,61,62,63,64,65]\n",
    "\n",
    "        # decent features - eyeballed\n",
    "\n",
    "        # generate set of selected features\n",
    "        selected_features = []\n",
    "\n",
    "        for figure_num in selected_figures:\n",
    "            for i in range(0,4):\n",
    "                # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "                selected_features.append((figure_num*4)+i)\n",
    "\n",
    "        # to add possible features\n",
    "        if ADD_POSSIBLE_FIGURES == True:\n",
    "            for figure_num in possible_figures:\n",
    "                for i in range(0,4):\n",
    "                    # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "                    selected_features.append((figure_num*4)+i)\n",
    "                    \n",
    "        training_data = training_data[selected_features]\n",
    "        testing_data = testing_data[selected_features]\n",
    "    else:\n",
    "        print('no feature selection')\n",
    "\n",
    "    # FSv2\n",
    "    if FEATURE_SELECTv2:    \n",
    "        # selected features round 2\n",
    "        selected_features = []\n",
    "        a = np.arange(30,85).tolist()\n",
    "        b = np.arange(203,235).tolist()\n",
    "\n",
    "        selected_features = np.concatenate([a,b]).tolist()\n",
    "        print(selected_features)\n",
    "        # (Cena, 2018)\n",
    "        training_data = training_data[selected_features]\n",
    "        testing_data = testing_data[selected_features]\n",
    "    else:\n",
    "        print('no FSv2')\n",
    "\n",
    "    # SNV\n",
    "    # apply SNV to training data - inspired by code from my ML CW\n",
    "    # (Hamzah Hafejee, 2022, COMP3611_Coursework_Assessment.ipynb, Comp 3611, University of Leeds)\n",
    "    # (Sklearn, 2023)\n",
    "    if SNV == True:\n",
    "        print(len(training_data))\n",
    "        # fit to training data\n",
    "        scaler = StandardScaler().fit(training_data)\n",
    "        training_data = scaler.transform(training_data)\n",
    "        testing_data = scaler.transform(testing_data)\n",
    "        print(\"After: \\n\", len(training_data))\n",
    "        len(training_data)\n",
    "    else:\n",
    "        print('no SNV standardisation')\n",
    "\n",
    "    #### train the models ####\n",
    "\n",
    "    # CART\n",
    "    # bayes search experiment (Skopt, 2017)\n",
    "    clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "    # find optimal parameter values for CART\n",
    "    NoneList = [None]\n",
    "    NumList = range(1,40)\n",
    "    for num in NumList:\n",
    "        NoneList.append(num)\n",
    "\n",
    "    params = {\n",
    "        'max_depth': Categorical(NoneList), # control overfitting,\n",
    "        'max_features': Categorical([None, 'sqrt', 'log2']) # performance \n",
    "    }\n",
    "    \n",
    "    bayes_search = BayesSearchCV(clf_cart, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_cart = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['CART'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make Gaussian Naive Bayes classifier\n",
    "    clf_nb = GaussianNB()\n",
    "    params = {\n",
    "        # use log-uniform for quicker convergence (Lewinson, 2022)\n",
    "        'var_smoothing':Real(1e-20, 0.1, prior='log-uniform') # from less smoothing to more aggressive smoothing\n",
    "    }\n",
    "    bayes_search = BayesSearchCV(clf_nb, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_nb = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['GNB'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make k-Nearest Neighbours classifier\n",
    "    clf_knn = KNeighborsClassifier(n_jobs=-1) # use all processes for parellelisation\n",
    "    params = {\n",
    "        'n_neighbors': Integer(1,15)\n",
    "    }\n",
    "    bayes_search = BayesSearchCV(clf_knn, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_knn = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['kNN'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make SVM-RBF classifier\n",
    "    clf_svmrbf = SVC(kernel='rbf', random_state=1)\n",
    "    params = {\n",
    "        'C': Real(0.1,5000, prior='log-uniform'), # high to low regularisation strength\n",
    "        'gamma' : Categorical(['scale', 'auto']), # need to research this parameter more\n",
    "    }\n",
    "\n",
    "    bayes_search = BayesSearchCV(clf_svmrbf, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_svmrbf = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['SVM-RBF'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make SVM linear classifier\n",
    "    clf_lin = SVC(kernel='linear', random_state=1)\n",
    "    params = {\n",
    "        # the different SVM kernels have different C values as I adjusetd it after seeing\n",
    "        # how previous experiments went and where they most commonly performed best\n",
    "        'C': Real(0.05, 1000, prior='log-uniform'), # high to low regularisation strength\n",
    "        'gamma' : Categorical(['scale', 'auto']), # need to research this parameter more\n",
    "        # 'gamma' : [], # need to research this parameter more - remember i started off \n",
    "        # testing each param separately to lower range of values for each \n",
    "    }\n",
    "\n",
    "    bayes_search = BayesSearchCV(clf_lin, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_svmlin = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['SVM-Lin'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make svm sigmoidal classifier\n",
    "    clf_sig = SVC(kernel='sigmoid', random_state=1)\n",
    "    params = {\n",
    "        'C': Real(0.00001, 100, prior='log-uniform'), # high to low regularisation strength\n",
    "        'gamma' : Categorical(['scale', 'auto']), # need to research this parameter more\n",
    "        # 'gamma' : [], # need to research this parameter more\n",
    "    }\n",
    "        \n",
    "    bayes_search = BayesSearchCV(clf_sig, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_svmsig = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['SVM-Sig'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make xgboost classifier (Piotr Płoński, 2021)\n",
    "    clf_xgb = xgb.XGBClassifier(random_state = 1)\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': Integer(10, 1000, prior='log-uniform'), # no. boosting rounds\n",
    "        'max_depth': Integer(1,30) # control overfitting\n",
    "    }\n",
    "\n",
    "    bayes_search = BayesSearchCV(clf_xgb, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_xgb = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['XGB'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # make adaboost classifier\n",
    "    clf_ada = AdaBoostClassifier(random_state=1)\n",
    "    params = {\n",
    "        'n_estimators': Integer(10,1000,prior='log-uniform'),\n",
    "        'learning_rate': Real(0.001, 10, prior='log-uniform') # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "    bayes_search = BayesSearchCV(clf_ada, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_ada = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['ADA'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "    # # make Logistic Regressor\n",
    "    # clf_lr = LogisticRegression(random_state=1, max_iter=1000)\n",
    "    # params = {\n",
    "    #     'penalty': ['l1', 'l2'], # type of regularisation \n",
    "    #     'C': [0.1, 1, 10, 100], # regularisation strength\n",
    "    #     'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'] # approach to finding best weights\n",
    "    # }\n",
    "\n",
    "    # # print(DATASET)\n",
    "\n",
    "    # if DATASET == 'raw':\n",
    "    #     # raw dataset\n",
    "    #     params = {\n",
    "    #         'penalty': ['l2'], # type of regularisation \n",
    "    #         'C': [0.1], # regularisation strength\n",
    "    #         'solver': ['lbfgs'] # approach to finding best weights\n",
    "    #     }\n",
    "    # elif DATASET == 'feature_select':\n",
    "    #     # selected + possible features\n",
    "    #     params = {\n",
    "    #         'penalty': ['l2'], # type of regularisation \n",
    "    #         'C': [0.1], # regularisation strength\n",
    "    #         'solver': ['newton-cg'] # approach to finding best weights\n",
    "    #     }\n",
    "    # elif DATASET == 'feature_selectv2':\n",
    "    #     # FSv2\n",
    "    #     params = {'C': [1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "    # elif DATASET == 'snv_raw':\n",
    "    #     # SNV + raw\n",
    "    #     params = {'C': [0.1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "    # elif DATASET == 'balanced':\n",
    "    #     params = {'C': [100], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    # elif DATASET == 'snv_balanced':\n",
    "    #     params = {'C': [0.1], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "\n",
    "    # elif DATASET == 'my_balanced':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "        \n",
    "    # elif DATASET == 'FS_my_balanced':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "        \n",
    "    # elif DATASET == 'FSv2_my_balanced':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "        \n",
    "    # elif DATASET == 'snv_my_balanced':\n",
    "    #     params = {'C': [1], 'penalty': ['l1'], 'solver': ['saga']} \n",
    "        \n",
    "    # elif DATASET == 'snv_FS_my_balanced':\n",
    "    #     params = {'C': [1], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "        \n",
    "    # elif DATASET == 'augmented':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "        \n",
    "    # elif DATASET == 'augmented_FS':\n",
    "    #     params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "\n",
    "    # elif DATASET == 'smote':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "\n",
    "    # elif DATASET == 'augmentedv3':\n",
    "    #     params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "        \n",
    "    # elif DATASET == 'snv_augmentedv3':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "        \n",
    "    # elif DATASET == 'snv_FS_my_balanced':\n",
    "    #     params = {'C': [10], 'penalty': ['l1'], 'solver': ['saga']} \n",
    "\n",
    "    # elif DATASET == 'augmentedv3_FS':\n",
    "    #     params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "        \n",
    "    # elif DATASET == 'svmsmote':\n",
    "    #     params = {'C': [100], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "        \n",
    "    # elif DATASET == 'kmeanssmote':\n",
    "    #     params = {'C': [10], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "        \n",
    "    # elif DATASET == 'adasynsmote':\n",
    "    #     params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "        \n",
    "    # elif DATASET == 'bordersmote':\n",
    "    #     params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "        \n",
    "    # elif DATASET == 'snv_svmsmote':\n",
    "    #     params = {'C': [100], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "        \n",
    "    # elif DATASET == 'snv_FS_svmsmote':\n",
    "    #     params = {'C': [100], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "        \n",
    "    # grid_search = GridSearchCV(clf_lr, params, scoring='accuracy', cv=10)\n",
    "    # grid_search.fit(training_data, np.ravel(training_labels))\n",
    "    # best_params = grid_search.best_params_\n",
    "    # best_score = grid_search.best_score_\n",
    "    # print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    # gs_results['LR'] = {'accuracy':best_score, 'params':best_params}\n",
    "    # best_lr = bayes_search.best_estimator_\n",
    "\n",
    "    \n",
    "    # make Random Forest classifier\n",
    "    clf_rf = RandomForestClassifier(random_state=1)\n",
    "    NoneList = [None]\n",
    "    NumList = range(1,50)\n",
    "    for num in NumList:\n",
    "        NoneList.append(num)\n",
    "        \n",
    "    params = {\n",
    "    'n_estimators': Integer(10,300,prior='log-uniform'),\n",
    "    'max_depth': Categorical(NoneList),\n",
    "    \"max_features\" : Categorical(NoneList)\n",
    "    }\n",
    "\n",
    "    bayes_search = BayesSearchCV(clf_rf, params, scoring='accuracy', cv=5, n_iter=100, random_state=1)\n",
    "    _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "    best_params = bayes_search.best_params_\n",
    "    best_score = bayes_search.best_score_\n",
    "    print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "    best_rf = bayes_search.best_estimator_\n",
    "    gs_results[DATASET]['RF'] = {'accuracy':best_score, 'params':best_params}\n",
    "\n",
    "\n",
    "    # ensemble model (Sklearn, 2014), (Sklearn, 2023)\n",
    "    ensemble = VotingClassifier(estimators=[\n",
    "        ('rf', best_rf), \n",
    "        ('knn', best_knn), \n",
    "        ('xgb', best_xgb), \n",
    "        ('svmrbf', best_svmrbf), \n",
    "        ('nb', best_nb)],\n",
    "        voting='hard',\n",
    "        n_jobs=-1)\n",
    "\n",
    "    ensemble.fit(training_data, training_labels)\n",
    "\n",
    "    accuracy = ensemble.score(testing_data, testing_labels)\n",
    "    predictions = ensemble.transform(testing_data)\n",
    "    gs_results[DATASET]['Ensemble'] = {'accuracy':accuracy}\n",
    "\n",
    "\n",
    "    # sorted GS models\n",
    "    print(gs_results)\n",
    "    # print params to file\n",
    "    with open(f'BOmetrics/params/{DATASET}', 'a+') as fp:\n",
    "        json.dump(gs_results, fp)\n",
    "        fp.close()\n",
    "\n",
    "    gs_sorted_models = dict(sorted(gs_results.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "    print(gs_sorted_models.keys())\n",
    "\n",
    "\n",
    "\n",
    "    # evaluate models (Sklearn, 2023)\n",
    "    # model_metrics = {'accuracy', 'recall', 'precision', 'F1-score', 'ROC-AUC'}\n",
    "    model_metrics = {}\n",
    "\n",
    "    # all of the models\n",
    "    models = [best_cart, best_rf, best_nb, best_knn, best_svmrbf, best_svmlin, best_svmsig, best_xgb, best_ada, ensemble]\n",
    "    model_names = ['CART', 'RF', 'GNB', 'kNN', 'SVM-RBF', 'SVM-Lin', 'SVM-Sig', 'XGB', 'ADA', 'Ensemble']\n",
    "    i=0\n",
    "    for model in models:\n",
    "        # train on test set\n",
    "        predicted = model.predict(testing_data)\n",
    "        # generate cm against test labels\n",
    "        cm = confusion_matrix(testing_labels, predicted)\n",
    "        # print(cm)\n",
    "        accuracy = accuracy_score(testing_labels, predicted)\n",
    "        recall = recall_score(testing_labels, predicted, average=None)\n",
    "        precision = precision_score(testing_labels, predicted, average=None)\n",
    "        f1 = f1_score(testing_labels, predicted, average=None)\n",
    "\n",
    "        try:\n",
    "            predicted_prob = model.predict_proba(testing_data)\n",
    "            roc = roc_auc_score(testing_labels, predicted_prob, average=None, multi_class='ovr') \n",
    "            # print(accuracy, recall, precision, f1, roc)\n",
    "            model_metrics[model_names[i]] = {\n",
    "                                                'accuracy':accuracy, \n",
    "                                                'recall':{\n",
    "                                                    1:recall[0], \n",
    "                                                    2:recall[1], \n",
    "                                                    3:recall[2]\n",
    "                                                },\n",
    "                                                'precision':{\n",
    "                                                    1:precision[0], \n",
    "                                                    2:precision[1], \n",
    "                                                    3:precision[2]\n",
    "                                                },\n",
    "                                                'f1_score':{\n",
    "                                                    1:f1[0], \n",
    "                                                    2:f1[1], \n",
    "                                                    3:f1[2]\n",
    "                                                },\n",
    "                                                'ROC-AUC':{\n",
    "                                                    1:roc[0], \n",
    "                                                    2:roc[1], \n",
    "                                                    3:roc[2]\n",
    "                                                }\n",
    "            }\n",
    "        except:\n",
    "            # print(f\"can't predict class probilities for {model_names[i]}\")\n",
    "            # print(accuracy, recall, precision, f1)\n",
    "            model_metrics[model_names[i]] = {\n",
    "                                                'accuracy':accuracy, \n",
    "                                                'recall':{\n",
    "                                                    1:recall[0], \n",
    "                                                    2:recall[1], \n",
    "                                                    3:recall[2]\n",
    "                                                },\n",
    "                                                'precision':{\n",
    "                                                    1:precision[0], \n",
    "                                                    2:precision[1], \n",
    "                                                    3:precision[2]\n",
    "                                                },\n",
    "                                                'f1_score':{\n",
    "                                                    1:f1[0], \n",
    "                                                    2:f1[1], \n",
    "                                                    3:f1[2]\n",
    "                                                }\n",
    "            }\n",
    "        i+=1\n",
    "\n",
    "    # (Gern Blanston, 2009)- sort by neoplasia recall\n",
    "    sorted_metrics = dict(sorted(model_metrics.items(), key=lambda item: item[1]['recall'][3], reverse=True))\n",
    "    # (holys, 2013)\n",
    "    with open(FILENAME_RECALL, 'w+') as fp:\n",
    "        json.dump(sorted_metrics, fp)\n",
    "        fp.close()\n",
    "\n",
    "    # redo but sort by accuracy\n",
    "    # (Gern Blanston, 2009)\n",
    "    sorted_metrics_acc = dict(sorted(model_metrics.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "    # (holys, 2013)\n",
    "    with open(FILENAME_ACC, 'w+') as fp:\n",
    "        json.dump(sorted_metrics_acc, fp)\n",
    "        fp.close()\n",
    "\n",
    "\n",
    "\n",
    "    # (Neekhara, 2019)\n",
    "    # DATASET = 'snv_svmsmote'\n",
    "    # function to add to JSON\n",
    "    def write_json(new_data, ds, filename='BOmetrics/scoreboard.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "            # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[ds] = (new_data)\n",
    "            file_data = dict(sorted(file_data.items(), key=lambda item: item[1]['all']['accuracy'], reverse=True))\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "            file.close()\n",
    "\n",
    "    # calculate avg accuracy and recall\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    count = 0\n",
    "    for model in model_names:\n",
    "        # print(model_metrics[model]['accuracy'])\n",
    "        accuracy += model_metrics[model]['accuracy']\n",
    "        recall += model_metrics[model]['recall'][3]\n",
    "        count +=1\n",
    "\n",
    "    t6acc = 0\n",
    "    t6rec = 0\n",
    "    count2 = 0\n",
    "    for key in sorted_metrics_acc:\n",
    "        if count2 ==6:\n",
    "            break\n",
    "        t6acc += sorted_metrics_acc[key]['accuracy']\n",
    "        t6rec += sorted_metrics_acc[key]['recall'][3]\n",
    "        count2 +=1\n",
    "\n",
    "    avg = {'all' : {'accuracy': accuracy/count, 'neoplasia recall': recall/count},\n",
    "        'top6' : {'accuracy': t6acc/count2, 'recall':t6rec/count2}}\n",
    "    # print(accuracy, recall, count)\n",
    "    # print(t6acc, t6rec, count2)\n",
    "    if DATASET != 'test':\n",
    "        write_json(avg, ds=DATASET)\n",
    "    else:\n",
    "        print(DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 433)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature_selectv2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO USE AVG RECALL AS METRIC FOR GS\n",
    "# (gunes, 2019)\n",
    "gs_recall = make_scorer(recall_score, average='macro')\n",
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_sorted_models (acc): \n",
      "dict_keys(['SVM-RBF', 'RF', 'XGB', 'kNN', 'Ensemble', 'CART', 'SVM-Lin', 'LR', 'ADA', 'SVM-Sig', 'GNB'])\n",
      "\n",
      "sorted models (acc): \n",
      "dict_keys(['SVM-RBF', 'Ensemble', 'XGB', 'kNN', 'CART', 'RF', 'LR', 'SVM-Lin', 'GNB', 'ADA', 'SVM-Sig'])\n",
      "\n",
      "sorted models (recall): \n",
      "dict_keys(['GNB', 'SVM-RBF', 'CART', 'kNN', 'Ensemble', 'XGB', 'LR', 'RF', 'SVM-Lin', 'SVM-Sig', 'ADA'])\n"
     ]
    }
   ],
   "source": [
    "# print highest acc models from gridsearch\n",
    "print(f\"gs_sorted_models (acc): \\n{gs_sorted_models.keys()}\\n\")\n",
    "\n",
    "# highest acc models from test set\n",
    "print(f\"sorted models (acc): \\n{sorted_metrics_acc.keys()}\\n\")\n",
    "\n",
    "# highest recall from test set\n",
    "print(f\"sorted models (recall): \\n{sorted_metrics.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature_selectv2'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7832167832167825 5.258620689655172 11\n",
      "4.538461538461538 3.5172413793103448 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': {'accuracy': 0.7075651621106166,\n",
       "  'neoplasia recall': 0.47805642633228834},\n",
       " 'top6': {'accuracy': 0.7564102564102564, 'recall': 0.5862068965517241}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "avg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observations on raw dataset\n",
    "XGBoost and ADAboost seem to have really overfit, because they severely underperform on unseen test data, compared to the accuracies they were achieving with gridsearch. IGNORE THIS: it is just because the test labels were not normalised!\n",
    "\n",
    "Although GNB has higher recall for neoplasia than kNN, kNN seems to be the best classifier overall. While GNB has highest recall for neoplasia, has 3rd lowest accuracy.\n",
    "\n",
    "Top models based on accuracy, from gridsearch, were RF, kNN, XGB, SVM-RBF, CART. Top models based on accuracy, from test set, were RF, kNN, SVM-RBF, CART, SVM-Lin. Therefore, RF, kNN, SVM-RBF, CART seem to perform well, in terms of accuracy, and don't seem to produce drastically different results with the test set, suggesting there isn't much overfitting\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'kNN', 'XGB', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'ADA', 'SVM-Sig', 'GNB'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'SVM-Lin', 'LR', 'SVM-Sig', 'GNB', 'ADA'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'kNN', 'CART', 'RF', 'SVM-Lin', 'XGB', 'LR', 'SVM-RBF', 'SVM-Sig', 'ADA'])\n",
    "\n",
    "# observations on feature selected dataset\n",
    "Some models decreased in performance, some increased, with largest increase being 6% increase in accuracy for SVM-Lin model. But overall, not worth, since the max accuracy of any of the models was lower than without feature selection. Maybe better feature selection is needed - an analytical solution rather than eyeball\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'SVM-RBF', 'kNN', 'XGB', 'CART', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'GNB', 'ADA', 'SVM-Sig'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'SVM-RBF', 'XGB', 'RF', 'kNN', 'SVM-Lin', 'CART', 'LR', 'SVM-Sig', 'ADA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69968d942e1dcc7d0770d34dbcb974701730c09224194d51fbd302d9296a213d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
