{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find standalone models with highest accuracy from all experiments\n",
    "### Top 3\n",
    "\n",
    "1. SVMSMOTE - RF: 87.4% acc\n",
    "2. SNV_AUGMENTEDV3 - RF: 86.7% acc\n",
    "3. RAW - Ensemble [rf, knn, xgb, svmrbf, nb]: 86% acc (poor recall 67.2%)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find standalone models with highest recall from all experiments\n",
    "This one was a bit tricky, since many models, such as GNB and SVM-Sig produced very high neoplasia recall, but had very low accuracy overall. Hence, I filtered out any models with less than 75% acc\n",
    "\n",
    "### Top 3\n",
    "\n",
    "1. FS_AUGMENTED - CART: 82.8% rec\n",
    "2. SNV_AUGMENTEDV3 - KNN: 81% rec\n",
    "3. SNV_FS_BALANCED: kNN: 78.9% rec\n",
    "\n",
    "\n",
    "\n",
    "### Honorable mention\n",
    "4. AUGMENTEDV3 - RF & kNN: 75.9% rec *2nd highest scoring standalone model in acc (86.7%) & (80.4% acc)\n",
    "4. KMEANSSMOTE - kNN: 75.9% rec (83.9% acc)\n",
    "5. SVMSMOTE: RF: 74% rec *highest scoring standalone model in acc (87.4%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: ['snv_FS_balanced', 'svmsmote', 'snv_FS_svmsmote', 'raw', 'kmeanssmote', 'balanced', 'snv_balanced', 'augmentedv2', 'feature_select', 'bordersmote', 'smote', 'snv_svmsmote', 'adasynsmote', 'augmented', 'augmentedv3', 'snv_raw', 'snv_augmentedv3', 'my_balancedv2', 'augmented_FS', 'augmentedv2_FS', 'augmentedv3_FS', 'feature_selectv2']\n",
      "rec: ['augmentedv3_FS', 'snv_augmentedv3', 'augmentedv3', 'augmented_FS', 'bordersmote', 'snv_FS_svmsmote', 'my_balancedv2', 'svmsmote', 'augmentedv2', 'augmented', 'adasynsmote', 'snv_svmsmote', 'kmeanssmote', 'augmentedv2_FS', 'raw', 'smote', 'snv_raw', 'feature_select', 'feature_selectv2', 'balanced', 'snv_FS_balanced', 'snv_balanced']\n",
      "dic: \n",
      "{\"snv_FS_balanced\": [22, {\"acc_rank\": 1, \"rec_rank\": 21}], \"svmsmote\": [10, {\"acc_rank\": 2, \"rec_rank\": 8}], \"snv_FS_svmsmote\": [9, {\"acc_rank\": 3, \"rec_rank\": 6}], \"raw\": [19, {\"acc_rank\": 4, \"rec_rank\": 15}], \"kmeanssmote\": [18, {\"acc_rank\": 5, \"rec_rank\": 13}], \"balanced\": [26, {\"acc_rank\": 6, \"rec_rank\": 20}], \"snv_balanced\": [29, {\"acc_rank\": 7, \"rec_rank\": 22}], \"augmentedv2\": [17, {\"acc_rank\": 8, \"rec_rank\": 9}], \"feature_select\": [27, {\"acc_rank\": 9, \"rec_rank\": 18}], \"bordersmote\": [15, {\"acc_rank\": 10, \"rec_rank\": 5}], \"smote\": [27, {\"acc_rank\": 11, \"rec_rank\": 16}], \"snv_svmsmote\": [24, {\"acc_rank\": 12, \"rec_rank\": 12}], \"adasynsmote\": [24, {\"acc_rank\": 13, \"rec_rank\": 11}], \"augmented\": [24, {\"acc_rank\": 14, \"rec_rank\": 10}], \"augmentedv3\": [18, {\"acc_rank\": 15, \"rec_rank\": 3}], \"snv_raw\": [33, {\"acc_rank\": 16, \"rec_rank\": 17}], \"snv_augmentedv3\": [19, {\"acc_rank\": 17, \"rec_rank\": 2}], \"my_balancedv2\": [25, {\"acc_rank\": 18, \"rec_rank\": 7}], \"augmented_FS\": [23, {\"acc_rank\": 19, \"rec_rank\": 4}], \"augmentedv2_FS\": [34, {\"acc_rank\": 20, \"rec_rank\": 14}], \"augmentedv3_FS\": [22, {\"acc_rank\": 21, \"rec_rank\": 1}], \"feature_selectv2\": [41, {\"acc_rank\": 22, \"rec_rank\": 19}]} \n",
      "len(keys): 22\n"
     ]
    }
   ],
   "source": [
    "# function to sort scoreboard\n",
    "import json\n",
    "def sort_scores(filename='metrics/scoreboard.json'):\n",
    "    with open(filename,'r') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        acc_sort = dict(sorted(file_data.items(), key=lambda item: item[1]['top6']['accuracy'], reverse=True))\n",
    "        rec_sort = dict(sorted(file_data.items(), key=lambda item: item[1]['top6']['recall'], reverse=True))\n",
    "\n",
    "    with open('metrics/top6acc.json', 'w') as new_file:\n",
    "        json.dump(acc_sort, new_file, indent = 4)\n",
    "    acc_keys = list(acc_sort.keys())\n",
    "    print('acc:',list(acc_sort.keys()))\n",
    "\n",
    "    with open('metrics/top6rec.json', 'w') as new_file:\n",
    "        json.dump(rec_sort, new_file, indent = 4)\n",
    "    rec_keys = list(rec_sort.keys())\n",
    "    print('rec:',list(rec_sort.keys()))\n",
    "\n",
    "    dic = {}\n",
    "    # make dic keys\n",
    "    for key in acc_keys:\n",
    "        dic[key] = []\n",
    "\n",
    "    for key in acc_keys:\n",
    "        acc_rank = acc_keys.index(key)+1\n",
    "        rec_rank = rec_keys.index(key)+1\n",
    "        dic[key] = [acc_rank + rec_rank, {'acc_rank':acc_rank, 'rec_rank':rec_rank}]\n",
    "    \n",
    "    sorted_dic = dict(sorted(dic.items(), key=lambda item: item[1][0]))\n",
    "    with open('metrics/rank_sums.json', 'w') as rank:\n",
    "        json.dump(sorted_dic, rank, indent = 4)\n",
    "\n",
    "    print(f\"dic: \\n{json.dumps(dic)} \\nlen(keys): {len(acc_keys)}\")\n",
    "sort_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best overall experiments (based on top 6 accuracy and recall)\n",
    "The difference between #1 accuracy-ranked experiment and last place is 0.83 - 0.775 = 0.055, i.e. 5.5% accuracy difference\n",
    "\n",
    "The difference between #1 recall-ranked experiment and last place is 0.741 - 0.439 = 0.302, i.e. 30.2% recall difference\n",
    "\n",
    "Hence, while the ranked sums is useful, it isn't fair to equally weight accuracy and recall rank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will optimise best overall experiments using bayesian optimisation, to try and further optimise models\n",
    "\n",
    "Might tweak class weights to get better recall\n",
    "\n",
    "Then will find best ensemble model\n",
    "\n",
    "Then will end implementation there"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
