{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import os, json\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train\n",
    "training_data = pd.read_csv('../data/original_data/noExclusion_train_data.csv', header = None)\n",
    "# y_train\n",
    "training_labels = pd.read_csv('../data/original_data/noExclusion_train_label.csv', header = None)\n",
    "# x_test\n",
    "testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "# y_test\n",
    "testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type cast labels to ints\n",
    "training_labels[0] = training_labels[0].astype(int)\n",
    "# testing_labels\n",
    "testing_labels[0] = testing_labels[0].astype(int)\n",
    "\n",
    "# encode labels, using sklearn, to pass to xgboost\n",
    "# this code was inspired by the snippet from:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "# fit the classes to the encoder and transform labels to be 0,1,2\n",
    "training_labels = le.fit_transform(training_labels[0].to_list())\n",
    "testing_labels = le.fit_transform(testing_labels[0].to_list())\n",
    "\n",
    "# gridsearch results\n",
    "gs_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply SNV to training data - inspired by code from my ML CW\n",
    "# (Hamzah Hafejee, 2022, COMP3611_Coursework_Assessment.ipynb, Comp 3611, University of Leeds)\n",
    "# (Anon, 2023b)\n",
    "print(type(training_data))\n",
    "# fit to training data\n",
    "scaler = StandardScaler().fit(training_data)\n",
    "training_data = scaler.transform(training_data)\n",
    "testing_data = scaler.transform(testing_data)\n",
    "print(\"After: \\n\", type(training_data))\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 203 is out of bounds for axis 0 with size 143",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39m# (Cena, 2018)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m training_data \u001b[39m=\u001b[39m training_data[selected_features]\n\u001b[1;32m---> 38\u001b[0m testing_data \u001b[39m=\u001b[39m testing_data[selected_features]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 203 is out of bounds for axis 0 with size 143"
     ]
    }
   ],
   "source": [
    "# RUN THIS TO APPLY FEATURE SELECTION TO TRAINING DATA\n",
    "ADD_POSSIBLE_FIGURES = True\n",
    "\n",
    "# figures contain features from (figure_num*4)+1 \n",
    "selected_figures = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                    21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\n",
    "                    39,40,41,42,43,44,45,46,47,48,49,50,51,52]\n",
    "\n",
    "# figures that MAY be decent - noisy but different peaks\n",
    "possible_figures = [53,54,56,57,58,59,60,61,62,63,64,65]\n",
    "\n",
    "# decent features - eyeballed\n",
    "\n",
    "# generate set of selected features\n",
    "selected_features = []\n",
    "\n",
    "for figure_num in selected_figures:\n",
    "    for i in range(0,4):\n",
    "        # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "        selected_features.append((figure_num*4)+i)\n",
    "\n",
    "# to add possible features\n",
    "if ADD_POSSIBLE_FIGURES == True:\n",
    "    for figure_num in possible_figures:\n",
    "        for i in range(0,4):\n",
    "            # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "            selected_features.append((figure_num*4)+i)\n",
    "\n",
    "# selected features round 2\n",
    "selected_features = []\n",
    "a = np.arange(30,85).tolist()\n",
    "b = np.arange(203,235).tolist()\n",
    "\n",
    "selected_features = np.concatenate([a,b]).tolist()\n",
    "print(selected_features)\n",
    "# (Cena, 2018)\n",
    "training_data = training_data[selected_features]\n",
    "testing_data = testing_data[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': None, 'max_features': 'log2'} \n",
      "best_score: 0.806019358741682\n"
     ]
    }
   ],
   "source": [
    "# make CART classifier\n",
    "clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "# find optimal parameter values for CART\n",
    "params = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30, 35, 40], # control overfitting,\n",
    "    'max_features': [None, 'sqrt', 'log2'] # performance \n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'max_depth': [None], # control overfitting,\n",
    "    'max_features': ['log2'] # performance \n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'max_depth': [5], # control overfitting,\n",
    "#     'max_features': [None] # performance \n",
    "# }\n",
    "\n",
    "# feature select v2\n",
    "# params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "\n",
    "# SNV + raw\n",
    "# params = {'max_depth': [None], 'max_features': ['log2']} \n",
    "\n",
    "grid_search = GridSearchCV(clf_cart, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_cart = grid_search.best_estimator_\n",
    "gs_results['CART'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "best_score: 0.7658197217180883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# make Logistic Regressor\n",
    "clf_lr = LogisticRegression(random_state=1)\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'], # type of regularisation \n",
    "    'C': [0.1, 1, 10, 100], # regularisation strength\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'] # approach to finding best weights\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'penalty': ['l2'], # type of regularisation \n",
    "    'C': [0.1], # regularisation strength\n",
    "    'solver': ['lbfgs'] # approach to finding best weights\n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'penalty': ['l2'], # type of regularisation \n",
    "#     'C': [0.1], # regularisation strength\n",
    "#     'solver': ['newton-cg'] # approach to finding best weights\n",
    "# }\n",
    "\n",
    "# FSv2\n",
    "# params = {'C': [1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "\n",
    "# SNV + raw\n",
    "# params = {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
    "\n",
    "grid_search = GridSearchCV(clf_lr, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "gs_results['LR'] = {'accuracy':best_score, 'params':best_params}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "best_score: 0.7658197217180883\n"
     ]
    }
   ],
   "source": [
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_lr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'var_smoothing': 1e-20} \n",
      "best_score: 0.6347549909255898\n"
     ]
    }
   ],
   "source": [
    "# make Gaussian Naive Bayes classifier\n",
    "clf_nb = GaussianNB()\n",
    "params = {\n",
    "    'var_smoothing':[1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9], # from less smoothing to more aggressive smoothing\n",
    "}\n",
    "grid_search = GridSearchCV(clf_nb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_nb = grid_search.best_estimator_\n",
    "gs_results['GNB'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'n_neighbors': 1} \n",
      "best_score: 0.8496067755595886\n"
     ]
    }
   ],
   "source": [
    "# make k-Nearest Neighbours classifier\n",
    "clf_knn = KNeighborsClassifier(n_jobs=-1) # use all processes for parellelisation\n",
    "params = {\n",
    "    'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "}\n",
    "grid_search = GridSearchCV(clf_knn, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_knn = grid_search.best_estimator_\n",
    "gs_results['kNN'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 100, 'gamma': 'scale'} \n",
      "best_score: 0.8357229280096792\n"
     ]
    }
   ],
   "source": [
    "# make SVM-RBF classifier\n",
    "clf_svmrbf = SVC(kernel='rbf', random_state=1)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'C': [100], # high to low regularisation strength\n",
    "    'gamma' : ['scale'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'C': [1000], # high to low regularisation strength\n",
    "#     'gamma' : ['scale'], # need to research this parameter more\n",
    "# }\n",
    "\n",
    "# selected + possible features v2\n",
    "# params = {\n",
    "#     'C': [1000], # high to low regularisation strength\n",
    "#     'gamma' : ['scale'], # need to research this parameter more\n",
    "# }\n",
    "\n",
    "# SNV + raw\n",
    "# params = {'C': 10, 'gamma': 'scale'} \n",
    "\n",
    "grid_search = GridSearchCV(clf_svmrbf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmrbf = grid_search.best_estimator_\n",
    "gs_results['SVM-RBF'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params = {'C': 10, 'gamma': 'scale'} \n",
      "best_score: 0.7553539019963702\n"
     ]
    }
   ],
   "source": [
    "# make SVM linear classifier\n",
    "clf_lin = SVC(kernel='linear', random_state=1)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'C': [10], # high to low regularisation strength\n",
    "    'gamma' : ['scale'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'C': [1], # high to low regularisation strength\n",
    "#     'gamma' : ['scale'], # need to research this parameter more\n",
    "# }\n",
    "\n",
    "# FSv2\n",
    "# params = {\n",
    "#     'C': [1], # high to low regularisation strength\n",
    "#     'gamma' : ['scale'], # need to research this parameter more\n",
    "# }\n",
    "\n",
    "# SNV + raw\n",
    "# best_params = {'C': 0.1, 'gamma': 'scale'} \n",
    "\n",
    "grid_search = GridSearchCV(clf_lin, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmlin = grid_search.best_estimator_\n",
    "gs_results['SVM-Lin'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 10, 'gamma': 'auto'} \n",
      "best_score: 0.6658802177858438\n"
     ]
    }
   ],
   "source": [
    "# make svm sigmoidal classifier\n",
    "clf_sig = SVC(kernel='sigmoid', random_state=1)\n",
    "params = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'C': [10], # high to low regularisation strength\n",
    "    'gamma' : ['auto'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'C': [1e-05], # high to low regularisation strength\n",
    "#     'gamma' : ['scale'], # need to research this parameter more\n",
    "# }\n",
    "\n",
    "# FSv2\n",
    "# params = {\n",
    "#     'C': [0.1], # high to low regularisation strength\n",
    "#     'gamma' : ['auto'], # need to research this parameter more\n",
    "# }\n",
    "\n",
    "# SNV + raw\n",
    "# params = {'C': 0.1, 'gamma': 'scale'} \n",
    "\n",
    "grid_search = GridSearchCV(clf_sig, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmsig = grid_search.best_estimator_\n",
    "gs_results['SVM-Sig'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': 10, 'n_estimators': 100} \n",
      "best_score: 0.8463399879007865\n"
     ]
    }
   ],
   "source": [
    "# make xgboost classifier\n",
    "clf_xgb = xgb.XGBClassifier(random_state = 1)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10,100, 500, 1000], # no. boosting rounds\n",
    "    'max_depth': [3,5,7,10,15] # control overfitting\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'n_estimators': [100], # no. boosting rounds\n",
    "    'max_depth': [10] # control overfitting\n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'n_estimators': [10], # no. boosting rounds\n",
    "#     'max_depth': [5] # control overfitting\n",
    "# }\n",
    "\n",
    "# FSv2\n",
    "# params = {\n",
    "#     'n_estimators': [100], # no. boosting rounds\n",
    "#     'max_depth': [5] # control overfitting\n",
    "# }\n",
    "\n",
    "# SNV + raw\n",
    "# params = {'max_depth': 10, 'n_estimators': 100} \n",
    "\n",
    "grid_search = GridSearchCV(clf_xgb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, training_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_xgb = grid_search.best_estimator_\n",
    "gs_results['XGB'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'learning_rate': 0.01, 'n_estimators': 50} \n",
      "best_score: 0.6696007259528131\n"
     ]
    }
   ],
   "source": [
    "# make adaboost classifier\n",
    "clf_ada = AdaBoostClassifier(random_state=1)\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100, 500, 1000],\n",
    "    'learning_rate': [0, 0.01, 0.1, 1, 10] # weight applied to each clf at each boosting iteration\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "    'n_estimators': [50],\n",
    "    'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "}\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#     'n_estimators': [10],\n",
    "#     'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "# }\n",
    "\n",
    "# FSv2\n",
    "# params = {\n",
    "#     'n_estimators': [50],\n",
    "#     'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "# }\n",
    "\n",
    "# SNV + raw\n",
    "# params = {'learning_rate': 0.01, 'n_estimators': 50} \n",
    "\n",
    "grid_search = GridSearchCV(clf_ada, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, training_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_ada = grid_search.best_estimator_\n",
    "gs_results['ADA'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': 10, 'max_features': 30, 'n_estimators': 50} \n",
      "best_score: 0.851482153660012\n"
     ]
    }
   ],
   "source": [
    "# make Random Forest classifier\n",
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "params = {\n",
    "  'n_estimators': [10, 50, 100, 200, 300],\n",
    "  'max_depth': [None, 5, 10, 20, 30, 40],\n",
    "  \"max_features\" : [None, 1, 5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# raw dataset\n",
    "params = {\n",
    "  'n_estimators': [50],\n",
    "  'max_depth': [10],\n",
    "  \"max_features\" : [30]\n",
    "}\n",
    "\n",
    "\n",
    "# selected + possible features\n",
    "# params = {\n",
    "#   'n_estimators': [200],\n",
    "#   'max_depth': [None],\n",
    "#   \"max_features\" : [5]\n",
    "# }\n",
    "\n",
    "# feature select v2\n",
    "# params = {'max_depth': [None], 'max_features': [5], 'n_estimators': [300]}\n",
    "\n",
    "# SNV + raw\n",
    "# params = {'max_depth': 10, 'max_features': 30, 'n_estimators': 50} \n",
    "\n",
    "\n",
    "grid_search  = GridSearchCV(clf_rf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_rf = grid_search.best_estimator_\n",
    "gs_results['RF'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601398601398601"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble model (Anon, 2014), (Anon, 2023b)\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf), \n",
    "    ('knn', best_knn), \n",
    "    ('xgb', best_xgb), \n",
    "    ('svmrbf', best_svmrbf), \n",
    "    ('nb', best_nb)],\n",
    "    voting='hard',\n",
    "    n_jobs=-1)\n",
    "\n",
    "ensemble.fit(training_data, training_labels)\n",
    "\n",
    "accuracy = ensemble.score(testing_data, testing_labels)\n",
    "predictions = ensemble.transform(testing_data)\n",
    "gs_results['Ensemble'] = {'accuracy':accuracy}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CART': {'accuracy': 0.806019358741682, 'params': {'max_depth': None, 'max_features': 'log2'}}, 'LR': {'accuracy': 0.7658197217180883, 'params': {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'GNB': {'accuracy': 0.6347549909255898, 'params': {'var_smoothing': 1e-20}}, 'kNN': {'accuracy': 0.8496067755595886, 'params': {'n_neighbors': 1}}, 'SVM-RBF': {'accuracy': 0.8357229280096792, 'params': {'C': 100, 'gamma': 'scale'}}, 'SVM-Lin': {'accuracy': 0.7553539019963702, 'params': {'C': 10, 'gamma': 'scale'}}, 'SVM-Sig': {'accuracy': 0.6658802177858438, 'params': {'C': 10, 'gamma': 'auto'}}, 'XGB': {'accuracy': 0.8463399879007865, 'params': {'max_depth': 10, 'n_estimators': 100}}, 'ADA': {'accuracy': 0.6696007259528131, 'params': {'learning_rate': 0.01, 'n_estimators': 50}}, 'RF': {'accuracy': 0.851482153660012, 'params': {'max_depth': 10, 'max_features': 30, 'n_estimators': 50}}, 'Ensemble': {'accuracy': 0.8601398601398601}}\n",
      "dict_keys(['Ensemble', 'RF', 'kNN', 'XGB', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'ADA', 'SVM-Sig', 'GNB'])\n"
     ]
    }
   ],
   "source": [
    "# sorted GS models\n",
    "print(gs_results)\n",
    "gs_sorted_models = dict(sorted(gs_results.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "print(gs_sorted_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't predict class probilities for SVM-RBF\n",
      "can't predict class probilities for SVM-Lin\n",
      "can't predict class probilities for SVM-Sig\n",
      "can't predict class probilities for Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GNB': {'accuracy': 0.6573426573426573,\n",
       "  'recall': {1: 1.0, 2: 0.47619047619047616, 3: 0.7241379310344828},\n",
       "  'precision': {1: 0.6470588235294118,\n",
       "   2: 0.6976744186046512,\n",
       "   3: 0.6363636363636364},\n",
       "  'f1_score': {1: 0.7857142857142858,\n",
       "   2: 0.5660377358490566,\n",
       "   3: 0.6774193548387097},\n",
       "  'ROC-AUC': {1: 0.9504132231404959,\n",
       "   2: 0.7593253968253968,\n",
       "   3: 0.7606490872210954}},\n",
       " 'kNN': {'accuracy': 0.8181818181818182,\n",
       "  'recall': {1: 0.9090909090909091,\n",
       "   2: 0.8888888888888888,\n",
       "   3: 0.7068965517241379},\n",
       "  'precision': {1: 0.9523809523809523,\n",
       "   2: 0.7567567567567568,\n",
       "   3: 0.8541666666666666},\n",
       "  'f1_score': {1: 0.9302325581395349,\n",
       "   2: 0.8175182481751826,\n",
       "   3: 0.7735849056603773},\n",
       "  'ROC-AUC': {1: 0.9504132231404959,\n",
       "   2: 0.8319444444444444,\n",
       "   3: 0.8122718052738336}},\n",
       " 'Ensemble': {'accuracy': 0.8601398601398601,\n",
       "  'recall': {1: 1.0, 2: 0.9841269841269841, 3: 0.6724137931034483},\n",
       "  'precision': {1: 0.9166666666666666, 2: 0.7848101265822784, 3: 0.975},\n",
       "  'f1_score': {1: 0.9565217391304348,\n",
       "   2: 0.8732394366197183,\n",
       "   3: 0.7959183673469388}},\n",
       " 'CART': {'accuracy': 0.7762237762237763,\n",
       "  'recall': {1: 0.9090909090909091,\n",
       "   2: 0.8412698412698413,\n",
       "   3: 0.6551724137931034},\n",
       "  'precision': {1: 0.8695652173913043,\n",
       "   2: 0.7464788732394366,\n",
       "   3: 0.7755102040816326},\n",
       "  'f1_score': {1: 0.888888888888889,\n",
       "   2: 0.791044776119403,\n",
       "   3: 0.7102803738317757},\n",
       "  'ROC-AUC': {1: 0.9421487603305786,\n",
       "   2: 0.8081349206349207,\n",
       "   3: 0.7628803245436105}},\n",
       " 'RF': {'accuracy': 0.8391608391608392,\n",
       "  'recall': {1: 0.9090909090909091,\n",
       "   2: 0.9841269841269841,\n",
       "   3: 0.6551724137931034},\n",
       "  'precision': {1: 0.9523809523809523,\n",
       "   2: 0.7469879518072289,\n",
       "   3: 0.9743589743589743},\n",
       "  'f1_score': {1: 0.9302325581395349,\n",
       "   2: 0.8493150684931506,\n",
       "   3: 0.7835051546391754},\n",
       "  'ROC-AUC': {1: 0.9977460555972953,\n",
       "   2: 0.9416666666666667,\n",
       "   3: 0.937525354969574}},\n",
       " 'SVM-Lin': {'accuracy': 0.7622377622377622,\n",
       "  'recall': {1: 1.0, 2: 0.7936507936507936, 3: 0.6379310344827587},\n",
       "  'precision': {1: 0.9166666666666666, 2: 0.7246376811594203, 3: 0.74},\n",
       "  'f1_score': {1: 0.9565217391304348,\n",
       "   2: 0.7575757575757576,\n",
       "   3: 0.6851851851851852}},\n",
       " 'XGB': {'accuracy': 0.8391608391608392,\n",
       "  'recall': {1: 1.0, 2: 0.9682539682539683, 3: 0.6379310344827587},\n",
       "  'precision': {1: 0.9565217391304348,\n",
       "   2: 0.7530864197530864,\n",
       "   3: 0.9487179487179487},\n",
       "  'f1_score': {1: 0.9777777777777777,\n",
       "   2: 0.8472222222222222,\n",
       "   3: 0.7628865979381444},\n",
       "  'ROC-AUC': {1: 0.9988730277986476,\n",
       "   2: 0.9232142857142857,\n",
       "   3: 0.9081135902636917}},\n",
       " 'LR': {'accuracy': 0.7272727272727273,\n",
       "  'recall': {1: 0.9545454545454546,\n",
       "   2: 0.7619047619047619,\n",
       "   3: 0.603448275862069},\n",
       "  'precision': {1: 0.875, 2: 0.6857142857142857, 3: 0.7142857142857143},\n",
       "  'f1_score': {1: 0.9130434782608695,\n",
       "   2: 0.7218045112781954,\n",
       "   3: 0.6542056074766354},\n",
       "  'ROC-AUC': {1: 0.9969947407963937,\n",
       "   2: 0.8331349206349206,\n",
       "   3: 0.8208924949290061}},\n",
       " 'SVM-RBF': {'accuracy': 0.8181818181818182,\n",
       "  'recall': {1: 1.0, 2: 0.9841269841269841, 3: 0.5689655172413793},\n",
       "  'precision': {1: 0.9166666666666666,\n",
       "   2: 0.7294117647058823,\n",
       "   3: 0.9705882352941176},\n",
       "  'f1_score': {1: 0.9565217391304348,\n",
       "   2: 0.8378378378378377,\n",
       "   3: 0.717391304347826}},\n",
       " 'SVM-Sig': {'accuracy': 0.6853146853146853,\n",
       "  'recall': {1: 0.8181818181818182,\n",
       "   2: 0.8253968253968254,\n",
       "   3: 0.4827586206896552},\n",
       "  'precision': {1: 0.72, 2: 0.65, 3: 0.7368421052631579},\n",
       "  'f1_score': {1: 0.7659574468085107,\n",
       "   2: 0.7272727272727272,\n",
       "   3: 0.5833333333333334}},\n",
       " 'ADA': {'accuracy': 0.5804195804195804,\n",
       "  'recall': {1: 0.9090909090909091, 2: 1.0, 3: 0.0},\n",
       "  'precision': {1: 0.9523809523809523, 2: 0.5163934426229508, 3: 0.0},\n",
       "  'f1_score': {1: 0.9302325581395349, 2: 0.6810810810810811, 3: 0.0},\n",
       "  'ROC-AUC': {1: 0.9922990232907588,\n",
       "   2: 0.7976190476190477,\n",
       "   3: 0.7883367139959432}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate models (Anon, 2023b)\n",
    "# model_metrics = {'accuracy', 'recall', 'precision', 'F1-score', 'ROC-AUC'}\n",
    "model_metrics = {}\n",
    "\n",
    "# all of the models\n",
    "models = [best_cart, best_rf, best_lr, best_nb, best_knn, best_svmrbf, best_svmlin, best_svmsig, best_xgb, best_ada, ensemble]\n",
    "model_names = ['CART', 'RF', 'LR', 'GNB', 'kNN', 'SVM-RBF', 'SVM-Lin', 'SVM-Sig', 'XGB', 'ADA', 'Ensemble']\n",
    "i=0\n",
    "for model in models:\n",
    "    # train on test set\n",
    "    predicted = model.predict(testing_data)\n",
    "    # generate cm against test labels\n",
    "    cm = confusion_matrix(testing_labels, predicted)\n",
    "    # print(cm)\n",
    "    accuracy = accuracy_score(testing_labels, predicted)\n",
    "    recall = recall_score(testing_labels, predicted, average=None)\n",
    "    precision = precision_score(testing_labels, predicted, average=None)\n",
    "    f1 = f1_score(testing_labels, predicted, average=None)\n",
    "\n",
    "    try:\n",
    "        predicted_prob = model.predict_proba(testing_data)\n",
    "        roc = roc_auc_score(testing_labels, predicted_prob, average=None, multi_class='ovr') \n",
    "        # print(accuracy, recall, precision, f1, roc)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            },\n",
    "                                            'ROC-AUC':{\n",
    "                                                1:roc[0], \n",
    "                                                2:roc[1], \n",
    "                                                3:roc[2]\n",
    "                                            }\n",
    "        }\n",
    "    except:\n",
    "        print(f\"can't predict class probilities for {model_names[i]}\")\n",
    "        # print(accuracy, recall, precision, f1)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            }\n",
    "        }\n",
    "    i+=1\n",
    "\n",
    "# (Gern Blanston, 2009)- sort by neoplasia recall\n",
    "sorted_metrics = dict(sorted(model_metrics.items(), key=lambda item: item[1]['recall'][3], reverse=True))\n",
    "# (holys, 2013)\n",
    "with open('metrics/raw_dataset/model_metrics_recall_ensemble.json', 'w') as fp:\n",
    "    json.dump(sorted_metrics, fp)\n",
    "\n",
    "# redo but sort by accuracy\n",
    "# (Gern Blanston, 2009)\n",
    "sorted_metrics_acc = dict(sorted(model_metrics.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "# (holys, 2013)\n",
    "with open('metrics/raw_dataset/model_metrics_accuracy_ensemble.json', 'w') as fp:\n",
    "    json.dump(sorted_metrics_acc, fp)\n",
    "model_metrics\n",
    "sorted_metrics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_sorted_models (acc): \n",
      "dict_keys(['Ensemble', 'RF', 'kNN', 'XGB', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'ADA', 'SVM-Sig', 'GNB'])\n",
      "\n",
      "sorted models (acc): \n",
      "dict_keys(['Ensemble', 'RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'SVM-Lin', 'LR', 'SVM-Sig', 'GNB', 'ADA'])\n",
      "\n",
      "sorted models (recall): \n",
      "dict_keys(['GNB', 'kNN', 'Ensemble', 'CART', 'RF', 'SVM-Lin', 'XGB', 'LR', 'SVM-RBF', 'SVM-Sig', 'ADA'])\n"
     ]
    }
   ],
   "source": [
    "# print highest acc models from gridsearch\n",
    "print(f\"gs_sorted_models (acc): \\n{gs_sorted_models.keys()}\\n\")\n",
    "\n",
    "# highest acc models from test set\n",
    "print(f\"sorted models (acc): \\n{sorted_metrics_acc.keys()}\\n\")\n",
    "\n",
    "# highest recall from test set\n",
    "print(f\"sorted models (recall): \\n{sorted_metrics.keys()}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observations on raw dataset\n",
    "XGBoost and ADAboost seem to have really overfit, because they severely underperform on unseen test data, compared to the accuracies they were achieving with gridsearch. IGNORE THIS: it is just because the test labels were not normalised!\n",
    "\n",
    "Although GNB has higher recall for neoplasia than kNN, kNN seems to be the best classifier overall. While GNB has highest recall for neoplasia, has 3rd lowest accuracy.\n",
    "\n",
    "Top models based on accuracy, from gridsearch, were RF, kNN, XGB, SVM-RBF, CART. Top models based on accuracy, from test set, were RF, kNN, SVM-RBF, CART, SVM-Lin. Therefore, RF, kNN, SVM-RBF, CART seem to perform well, in terms of accuracy, and don't seem to produce drastically different results with the test set, suggesting there isn't much overfitting\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'kNN', 'XGB', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'ADA', 'SVM-Sig', 'GNB'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'SVM-Lin', 'LR', 'SVM-Sig', 'GNB', 'ADA'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'kNN', 'CART', 'RF', 'SVM-Lin', 'XGB', 'LR', 'SVM-RBF', 'SVM-Sig', 'ADA'])\n",
    "\n",
    "# observations on feature selected dataset\n",
    "Some models decreased in performance, some increased, with largest increase being 6% increase in accuracy for SVM-Lin model. But overall, not worth, since the max accuracy of any of the models was lower than without feature selection. Maybe better feature selection is needed - an analytical solution rather than eyeball\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'SVM-RBF', 'kNN', 'XGB', 'CART', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'GNB', 'ADA', 'SVM-Sig'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'SVM-RBF', 'XGB', 'RF', 'kNN', 'SVM-Lin', 'CART', 'LR', 'SVM-Sig', 'ADA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69968d942e1dcc7d0770d34dbcb974701730c09224194d51fbd302d9296a213d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
