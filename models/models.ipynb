{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import os, json\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV, Optimizer\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toggle option\n",
    "SNV = False\n",
    "FEATURE_SELECT = False\n",
    "FEATURE_SELECTv2 = False\n",
    "BALANCED = False\n",
    "MY_BALANCED = False\n",
    "MY_BALANCEDv2 = False\n",
    "AUGMENTED = False # oversampling of neoplasia\n",
    "AUGMENTEDv2 = False # actual augmented\n",
    "AUGMENTEDv3 = False # augmented neoplasia only\n",
    "SMOTE = False\n",
    "SVMSMOTE = True\n",
    "TEST = True\n",
    "\n",
    "# Choose dataset\n",
    "DATASET = 'raw'\n",
    "FILENAME_ACC = 'metrics/raw_dataset/model_metrics_accuracy_ensemble.json'\n",
    "FILENAME_RECALL = 'metrics/raw_dataset/model_metrics_recall_ensemble.json'\n",
    "if TEST:\n",
    "    DATASET = 'test'\n",
    "    FILENAME_ACC = 'metrics/temp/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/temp/model_metrics_recall_ensemble.json'\n",
    "elif BALANCED:\n",
    "    DATASET = 'balanced'\n",
    "    FILENAME_ACC = 'metrics/balanced_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/balanced_dataset/model_metrics_recall_ensemble.json'\n",
    "    if SNV:\n",
    "        DATASET = 'snv_balanced'\n",
    "        FILENAME_ACC = 'metrics/balanced_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "        FILENAME_RECALL = 'metrics/balanced_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "        if FEATURE_SELECT:\n",
    "            DATASET = 'snv_FS_balanced'\n",
    "            FILENAME_ACC = 'metrics/balanced_dataset/model_metrics_accuracy_ensemble_snv_FS.json'\n",
    "            FILENAME_RECALL = 'metrics/balanced_dataset/model_metrics_recall_ensemble_snv_FS.json'\n",
    "elif MY_BALANCED:\n",
    "    DATASET = 'my_balanced'\n",
    "    FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble.json'\n",
    "    if FEATURE_SELECT:\n",
    "        DATASET = 'FS_my_balanced'\n",
    "        FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "        FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "        if SNV:\n",
    "            DATASET = 'snv_FS_my_balanced'\n",
    "            FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv_FS.json'\n",
    "            FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_snv_FS.json'\n",
    "    elif FEATURE_SELECTv2:\n",
    "        DATASET = 'FSv2_my_balanced'\n",
    "        FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_FSv2.json'\n",
    "        FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_FSv2.json'\n",
    "    elif SNV:\n",
    "        DATASET = 'snv_my_balanced'\n",
    "        FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "        FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "elif AUGMENTED:\n",
    "    DATASET = 'augmented'\n",
    "    FILENAME_ACC = 'metrics/augmented_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/augmented_dataset/model_metrics_recall_ensemble.json'\n",
    "    if FEATURE_SELECT:\n",
    "        DATASET = 'augmented_FS'\n",
    "        FILENAME_ACC = 'metrics/augmented_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "        FILENAME_RECALL = 'metrics/augmented_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "elif AUGMENTEDv2:\n",
    "    DATASET = 'augmentedv2'\n",
    "    FILENAME_ACC = 'metrics/augmentedv2_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/augmentedv2_dataset/model_metrics_recall_ensemble.json'\n",
    "    if FEATURE_SELECT:\n",
    "        DATASET = 'augmentedv2_FS'\n",
    "        FILENAME_ACC = 'metrics/augmentedv2_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "        FILENAME_RECALL = 'metrics/augmentedv2_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "elif AUGMENTEDv3:\n",
    "    DATASET = 'augmentedv3'\n",
    "    FILENAME_ACC = 'metrics/augmentedv3_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/augmentedv3_dataset/model_metrics_recall_ensemble.json'\n",
    "    if SNV:\n",
    "        DATASET = 'snv_augmentedv3'\n",
    "        FILENAME_ACC = 'metrics/augmentedv3_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "        FILENAME_RECALL = 'metrics/augmentedv3_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "    if FEATURE_SELECT:\n",
    "        DATASET = 'augmentedv3_FS'\n",
    "        FILENAME_ACC = 'metrics/augmentedv3_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "        FILENAME_RECALL = 'metrics/augmentedv3_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "elif SMOTE:\n",
    "    DATASET = 'smote'\n",
    "    FILENAME_ACC = 'metrics/smote/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/smote/model_metrics_recall_ensemble.json'\n",
    "elif SVMSMOTE:\n",
    "    DATASET = 'svmsmote'\n",
    "    FILENAME_ACC = 'metrics/svmsmote/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/svmsmote/model_metrics_recall_ensemble.json'\n",
    "elif MY_BALANCEDv2:\n",
    "    DATASET = 'my_balancedv2'\n",
    "    FILENAME_ACC = 'metrics/my_balancedv2_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/my_balancedv2_dataset/model_metrics_recall_ensemble.json'\n",
    "elif SNV:\n",
    "    DATASET = 'snv_raw'\n",
    "    FILENAME_ACC = 'metrics/raw_dataset/model_metrics_accuracy_snv.json'\n",
    "    FILENAME_RECALL = 'metrics/raw_dataset/model_metrics_recall_snv.json'\n",
    "elif FEATURE_SELECT:\n",
    "    DATASET = 'feature_select'\n",
    "    FILENAME_ACC = 'metrics/selected_features/model_metrics_accuracy.json'\n",
    "    FILENAME_RECALL = 'metrics/selected_features/model_metrics_recall.json'\n",
    "elif FEATURE_SELECTv2:\n",
    "    DATASET = 'feature_selectv2'\n",
    "    FILENAME_ACC = 'metrics/selected_features/model_metrics_accuracy2.json'\n",
    "    FILENAME_RECALL = 'metrics/selected_features/model_metrics_recall2.json'\n",
    "\n",
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmsmote\n"
     ]
    }
   ],
   "source": [
    "if MY_BALANCED:\n",
    "    print('my_balanced')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/balanced_data/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/balanced_data/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/balanced_data/test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/balanced_data/test_label.csv', header = None)\n",
    "elif BALANCED:\n",
    "    print('balanced')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/original_data/balanced_train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/original_data/balanced_train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/balanced_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/balanced_test_label.csv', header = None)\n",
    "elif AUGMENTED:\n",
    "    print('augmented')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/augmented_data/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/augmented_data/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "elif AUGMENTEDv2:\n",
    "    print('augmentedv2')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/augmented_datav2/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/augmented_datav2/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "elif AUGMENTEDv3:\n",
    "    print('augmentedv3')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/augmented_datav3/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/augmented_datav3/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "elif MY_BALANCEDv2:\n",
    "    print('my_balancedv2')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/balancedv2_data/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/balancedv2_data/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "elif SMOTE:\n",
    "    print('smote')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/SMOTE/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/SMOTE/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "elif SVMSMOTE:\n",
    "    print('svmsmote')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/SMOTE/svm/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/SMOTE/svm/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "else:\n",
    "    print('raw')\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/original_data/noExclusion_train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/original_data/noExclusion_train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data: <class 'pandas.core.frame.DataFrame'>, \n",
      "training_labels: <class 'pandas.core.frame.DataFrame'>, \n",
      "testing_data: <class 'pandas.core.frame.DataFrame'>, \n",
      "testing_labels: <class 'pandas.core.frame.DataFrame'>\n",
      "training labels vc: \n",
      "1    257\n",
      "2    257\n",
      "3    257\n",
      "dtype: int64, \n",
      "testing labels vc: \n",
      "2.0    63\n",
      "3.0    58\n",
      "1.0    22\n",
      "dtype: int64\n",
      "771 771 143 143\n"
     ]
    }
   ],
   "source": [
    "print(f\"training_data: {type(training_data)}, \\ntraining_labels: {type(training_labels)}, \\ntesting_data: {type(testing_data)}, \\ntesting_labels: {type(testing_labels)}\")\n",
    "print(f\"training labels vc: \\n{training_labels.value_counts()}, \\ntesting labels vc: \\n{testing_labels.value_counts()}\")\n",
    "print(len(training_data), len(training_labels), len(testing_data), len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type cast labels to ints\n",
    "training_labels[0] = training_labels[0].astype(int)\n",
    "# testing_labels\n",
    "testing_labels[0] = testing_labels[0].astype(int)\n",
    "\n",
    "# encode labels, using sklearn, to pass to xgboost\n",
    "# this code was inspired by the snippet from:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "# fit the classes to the encoder and transform labels to be 0,1,2\n",
    "training_labels = le.fit_transform(training_labels[0].to_list())\n",
    "testing_labels = le.fit_transform(testing_labels[0].to_list())\n",
    "\n",
    "# gridsearch results\n",
    "gs_results = {}\n",
    "np.unique(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no feature selection\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS TO APPLY FEATURE SELECTION TO TRAINING DATA\n",
    "if FEATURE_SELECT == True:\n",
    "    ADD_POSSIBLE_FIGURES = True\n",
    "\n",
    "    # figures contain features from (figure_num*4)+1 \n",
    "    selected_figures = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                        21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\n",
    "                        39,40,41,42,43,44,45,46,47,48,49,50,51,52]\n",
    "\n",
    "    # figures that MAY be decent - noisy but different peaks\n",
    "    possible_figures = [53,54,56,57,58,59,60,61,62,63,64,65]\n",
    "\n",
    "    # decent features - eyeballed\n",
    "\n",
    "    # generate set of selected features\n",
    "    selected_features = []\n",
    "\n",
    "    for figure_num in selected_figures:\n",
    "        for i in range(0,4):\n",
    "            # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "            selected_features.append((figure_num*4)+i)\n",
    "\n",
    "    # to add possible features\n",
    "    if ADD_POSSIBLE_FIGURES == True:\n",
    "        for figure_num in possible_figures:\n",
    "            for i in range(0,4):\n",
    "                # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "                selected_features.append((figure_num*4)+i)\n",
    "                \n",
    "    training_data = training_data[selected_features]\n",
    "    testing_data = testing_data[selected_features]\n",
    "else:\n",
    "    print('no feature selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no FSv2\n"
     ]
    }
   ],
   "source": [
    "if FEATURE_SELECTv2:    \n",
    "    # selected features round 2\n",
    "    selected_features = []\n",
    "    a = np.arange(30,85).tolist()\n",
    "    b = np.arange(203,235).tolist()\n",
    "\n",
    "    selected_features = np.concatenate([a,b]).tolist()\n",
    "    print(selected_features)\n",
    "    # (Cena, 2018)\n",
    "    training_data = training_data[selected_features]\n",
    "    testing_data = testing_data[selected_features]\n",
    "else:\n",
    "    print('no FSv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 433)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no SNV standardisation\n"
     ]
    }
   ],
   "source": [
    "# apply SNV to training data - inspired by code from my ML CW\n",
    "# (Hamzah Hafejee, 2022, COMP3611_Coursework_Assessment.ipynb, Comp 3611, University of Leeds)\n",
    "# (Sklearn, 2023)\n",
    "if SNV == True:\n",
    "    print(len(training_data))\n",
    "    # fit to training data\n",
    "    scaler = StandardScaler().fit(training_data)\n",
    "    training_data = scaler.transform(training_data)\n",
    "    testing_data = scaler.transform(testing_data)\n",
    "    print(\"After: \\n\", len(training_data))\n",
    "    len(training_data)\n",
    "else:\n",
    "    print('no SNV standardisation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO USE AVG RECALL AS METRIC FOR GS\n",
    "# (gunes, 2019)\n",
    "gs_recall = make_scorer(recall_score, average='macro')\n",
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': None, 'max_features': 'log2'} \n",
      "best_score: 0.8561105561105562\n"
     ]
    }
   ],
   "source": [
    "# make CART classifier\n",
    "clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "# find optimal parameter values for CART\n",
    "params = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30, 35, 40], # control overfitting,\n",
    "    'max_features': [None, 'sqrt', 'log2'] # performance \n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'max_depth': [None], # control overfitting,\n",
    "        'max_features': ['log2'] # performance \n",
    "    }\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'max_depth': [5], # control overfitting,\n",
    "        'max_features': [None] # performance \n",
    "    }\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # feature select v2\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'max_depth': [None], 'max_features': ['log2']} \n",
    "elif DATASET == 'balanced':\n",
    "    params = {'max_depth': [10], 'max_features': ['sqrt']} \n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "    \n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': ['log2']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [5], 'max_features': [None]} \n",
    "   \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'max_depth': [10], 'max_features': ['log2']} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'max_depth': [10], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "    params = {'max_depth': [15], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'max_depth': [None], 'max_features': ['log2']}\n",
    "    \n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'max_depth': [None], 'max_features': ['log2']}\n",
    " \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': [None]} \n",
    "\n",
    "grid_search = GridSearchCV(clf_cart, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_cart = grid_search.best_estimator_\n",
    "gs_results['CART'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bayes search experiment (Skopt, 2017)\n",
    "# clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "# # find optimal parameter values for CART\n",
    "# params = {\n",
    "#     'max_depth': Integer(1,100), # control overfitting,\n",
    "#     'max_features': Categorical([None, 'sqrt', 'log2']) # performance \n",
    "# }\n",
    "   \n",
    "# bayes_search = BayesSearchCV(clf_cart, params, scoring='accuracy', cv=10, random_state=1)\n",
    "# _ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "# best_params = bayes_search.best_params_\n",
    "# best_score = bayes_search.best_score_\n",
    "# print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "# best_cart = bayes_search.best_estimator_\n",
    "# gs_results['CART'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'var_smoothing': 1e-20} \n",
      "best_score: 0.6822510822510823\n"
     ]
    }
   ],
   "source": [
    "# make Gaussian Naive Bayes classifier\n",
    "clf_nb = GaussianNB()\n",
    "params = {\n",
    "    'var_smoothing':[1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9], # from less smoothing to more aggressive smoothing\n",
    "}\n",
    "grid_search = GridSearchCV(clf_nb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_nb = grid_search.best_estimator_\n",
    "gs_results['GNB'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'n_neighbors': 1} \n",
      "best_score: 0.9040626040626039\n"
     ]
    }
   ],
   "source": [
    "# make k-Nearest Neighbours classifier\n",
    "clf_knn = KNeighborsClassifier(n_jobs=-1) # use all processes for parellelisation\n",
    "params = {\n",
    "    'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "}\n",
    "grid_search = GridSearchCV(clf_knn, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_knn = grid_search.best_estimator_\n",
    "gs_results['kNN'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 5000, 'gamma': 'scale'} \n",
      "best_score: 0.90021645021645\n"
     ]
    }
   ],
   "source": [
    "# make SVM-RBF classifier\n",
    "clf_svmrbf = SVC(kernel='rbf', random_state=1)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000, 5000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'C': [100], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'C': [1000], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # selected + possible features v2\n",
    "    params = {\n",
    "        'C': [1000], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [1000], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [1000], 'gamma': ['scale']}\n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [100], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [100], 'gamma':[ 'scale']} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [5000], 'gamma':[ 'scale']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [100], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [5000], 'gamma':[ 'scale']} \n",
    "    \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'C': [5000], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'C': [5000], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "    params = {'C': [5000], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'C': [5000], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'C': [5000], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [5000], 'gamma': ['scale']} \n",
    "\n",
    "grid_search = GridSearchCV(clf_svmrbf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmrbf = grid_search.best_estimator_\n",
    "gs_results['SVM-RBF'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 1000, 'gamma': 'scale'} \n",
      "best_score: 0.7977355977355978\n"
     ]
    }
   ],
   "source": [
    "# make SVM linear classifier\n",
    "clf_lin = SVC(kernel='linear', random_state=1)\n",
    "params = {\n",
    "    'C': [0.05, 0.1, 1, 10, 100, 1000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'C': [10], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'C': [1], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'C': [1], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [1000], 'gamma':[ 'scale']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [0.05], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'C': [100], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'smote':\n",
    "    params = {'C': [1000], 'gamma':[ 'scale']} \n",
    "    \n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'C': [1000], 'gamma':[ 'scale']} \n",
    "\n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'C': [100], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [1], 'gamma': ['scale']} \n",
    "\n",
    "grid_search = GridSearchCV(clf_lin, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmlin = grid_search.best_estimator_\n",
    "gs_results['SVM-Lin'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 0.1, 'gamma': 'auto'} \n",
      "best_score: 0.4654678654678654\n"
     ]
    }
   ],
   "source": [
    "# make svm sigmoidal classifier\n",
    "clf_sig = SVC(kernel='sigmoid', random_state=1)\n",
    "params = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'C': [10], # high to low regularisation strength\n",
    "        'gamma' : ['auto'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'C': [1e-05], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'C': [0.1], # high to low regularisation strength\n",
    "        'gamma' : ['auto'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['auto']}\n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [1], 'gamma':[ 'auto']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'C': [100], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'C': [100], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "    params = {'C': [0.1], 'gamma': ['auto']} \n",
    "    \n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'C': [100], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'C': [0.01], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [1], 'gamma': ['scale']} \n",
    "\n",
    "grid_search = GridSearchCV(clf_sig, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmsig = grid_search.best_estimator_\n",
    "gs_results['SVM-Sig'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': 5, 'n_estimators': 500} \n",
      "best_score: 0.9001498501498502\n"
     ]
    }
   ],
   "source": [
    "# make xgboost classifier (Piotr Płoński, 2021)\n",
    "clf_xgb = xgb.XGBClassifier(random_state = 1)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10,100, 500, 1000], # no. boosting rounds\n",
    "    'max_depth': [3,5,7,10,15,20] # control overfitting\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'n_estimators': [100], # no. boosting rounds\n",
    "        'max_depth': [10] # control overfitting\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'n_estimators': [10], # no. boosting rounds\n",
    "        'max_depth': [5] # control overfitting\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'n_estimators': [100], # no. boosting rounds\n",
    "        'max_depth': [5] # control overfitting\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'max_depth': [10], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "    \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [500]} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [10], 'n_estimators': [100]} \n",
    "    \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'max_depth': [5], 'n_estimators': [500]} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'max_depth': [10], 'n_estimators': [1000]} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "    params = {'max_depth': [7], 'n_estimators': [500]} \n",
    "\n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'max_depth': [3], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'max_depth': [3], 'n_estimators': [100]} \n",
    "       \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [5], 'n_estimators': [500]} \n",
    "\n",
    "grid_search = GridSearchCV(clf_xgb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, training_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_xgb = grid_search.best_estimator_\n",
    "gs_results['XGB'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make adaboost classifier\n",
    "clf_ada = AdaBoostClassifier(random_state=1)\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100, 500, 1000],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1, 10] # weight applied to each clf at each boosting iteration\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'n_estimators': [50],\n",
    "        'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'n_estimators': [10],\n",
    "        'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'n_estimators': [50],\n",
    "        'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [10]} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [10]} \n",
    "    \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'learning_rate': [0.1], 'n_estimators': [10]} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "    \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "    \n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "\n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "        \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "\n",
    "grid_search = GridSearchCV(clf_ada, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, training_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_ada = grid_search.best_estimator_\n",
    "gs_results['ADA'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 10, 'penalty': 'l2', 'solver': 'saga'} \n",
      "best_score: 0.7847319347319347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# make Logistic Regressor\n",
    "clf_lr = LogisticRegression(random_state=1, max_iter=1000)\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'], # type of regularisation \n",
    "    'C': [0.1, 1, 10, 100], # regularisation strength\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'] # approach to finding best weights\n",
    "}\n",
    "\n",
    "print(DATASET)\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'penalty': ['l2'], # type of regularisation \n",
    "        'C': [0.1], # regularisation strength\n",
    "        'solver': ['lbfgs'] # approach to finding best weights\n",
    "    }\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'penalty': ['l2'], # type of regularisation \n",
    "        'C': [0.1], # regularisation strength\n",
    "        'solver': ['newton-cg'] # approach to finding best weights\n",
    "    }\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {'C': [1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [0.1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [100], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [0.1], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [1], 'penalty': ['l1'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [1], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'augmented':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "    \n",
    "elif DATASET == 'augmented_FS':\n",
    "    params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "\n",
    "elif DATASET == 'augmentedv3':\n",
    "    params = {'C': [100], 'penalty': ['l1'], 'solver': ['liblinear']} \n",
    "    \n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "    \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l1'], 'solver': ['saga']} \n",
    "\n",
    "grid_search = GridSearchCV(clf_lr, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "gs_results['LR'] = {'accuracy':best_score, 'params':best_params}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 10, 'penalty': 'l2', 'solver': 'saga'} \n",
      "best_score: 0.7847319347319347\n"
     ]
    }
   ],
   "source": [
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_lr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': None, 'max_features': 5, 'n_estimators': 50} \n",
      "best_score: 0.9092740592740591\n"
     ]
    }
   ],
   "source": [
    "# make Random Forest classifier\n",
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "params = {\n",
    "  'n_estimators': [10, 50, 100, 200, 300],\n",
    "  'max_depth': [None, 5, 10, 20, 30, 40],\n",
    "  \"max_features\" : [None, 1, 5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "  # raw dataset\n",
    "  params = {\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [10],\n",
    "    \"max_features\" : [30]\n",
    "  }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "  # selected + possible features\n",
    "  params = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [None],\n",
    "    \"max_features\" : [5]\n",
    "  }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "  # feature select v2\n",
    "  params = {'max_depth': [None], 'max_features': [5], 'n_estimators': [300]}\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "  # SNV + raw\n",
    "  params = {'max_depth': [10], 'max_features': [30], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [100]} \n",
    "  \n",
    "elif DATASET == 'my_balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [300]} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [300]} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "  params = {'max_depth': [None], 'max_features': [30], 'n_estimators': [100]} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [300]}\n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "  params = {'max_depth': [None], 'max_features': [10], 'n_estimators': [10]} \n",
    "\n",
    "elif DATASET == 'augmented':\n",
    "  params = {'max_depth': [None], 'max_features': [20], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'augmented_FS':\n",
    "  params = {'max_depth': [None], 'max_features': [1], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'smote':\n",
    "  params = {'max_depth': [None], 'max_features': [5], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'augmentedv3':\n",
    "  params = {'max_depth': [None], 'max_features': [10], 'n_estimators': [200]} \n",
    "\n",
    "elif DATASET == 'snv_augmentedv3':\n",
    "  params = {'max_depth': [None], 'max_features': [10], 'n_estimators': [200]} \n",
    "    \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "  params = {'max_depth': [None], 'max_features': [10], 'n_estimators': [300]} \n",
    "  \n",
    "grid_search  = GridSearchCV(clf_rf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_rf = grid_search.best_estimator_\n",
    "gs_results['RF'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391608391608392"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble model (Sklearn, 2014), (Sklearn, 2023)\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf), \n",
    "    ('knn', best_knn), \n",
    "    ('xgb', best_xgb), \n",
    "    ('svmrbf', best_svmrbf), \n",
    "    ('nb', best_nb)],\n",
    "    voting='hard',\n",
    "    n_jobs=-1)\n",
    "\n",
    "ensemble.fit(training_data, training_labels)\n",
    "\n",
    "accuracy = ensemble.score(testing_data, testing_labels)\n",
    "predictions = ensemble.transform(testing_data)\n",
    "gs_results['Ensemble'] = {'accuracy':accuracy}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CART': {'accuracy': 0.8574259074259075, 'params': {'max_depth': 15, 'max_features': 'sqrt'}}, 'GNB': {'accuracy': 0.7017149517149517, 'params': {'var_smoothing': 1e-20}}, 'kNN': {'accuracy': 0.9131868131868132, 'params': {'n_neighbors': 1}}, 'SVM-RBF': {'accuracy': 0.8963702963702962, 'params': {'C': 5000, 'gamma': 'scale'}}, 'SVM-Lin': {'accuracy': 0.8107392607392608, 'params': {'C': 1000, 'gamma': 'scale'}}, 'SVM-Sig': {'accuracy': 0.555044955044955, 'params': {'C': 0.1, 'gamma': 'auto'}}, 'XGB': {'accuracy': 0.908025308025308, 'params': {'max_depth': 7, 'n_estimators': 500}}, 'ADA': {'accuracy': 0.7717782217782216, 'params': {'learning_rate': 0.001, 'n_estimators': 1000}}, 'RF': {'accuracy': 0.9092740592740591, 'params': {'max_depth': None, 'max_features': 5, 'n_estimators': 50}}, 'LR': {'accuracy': 0.7847319347319347, 'params': {'C': 10, 'penalty': 'l2', 'solver': 'saga'}}, 'Ensemble': {'accuracy': 0.8391608391608392}}\n",
      "dict_keys(['kNN', 'RF', 'XGB', 'SVM-RBF', 'CART', 'Ensemble', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n"
     ]
    }
   ],
   "source": [
    "# sorted GS models\n",
    "print(gs_results)\n",
    "gs_sorted_models = dict(sorted(gs_results.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "print(gs_sorted_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't predict class probilities for SVM-RBF\n",
      "can't predict class probilities for SVM-Lin\n",
      "can't predict class probilities for SVM-Sig\n",
      "can't predict class probilities for Ensemble\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('metrics/smote/model_metrics_accuracy_ensemble.json',\n",
       " 'metrics/smote/model_metrics_recall_ensemble.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate models (Sklearn, 2023)\n",
    "# model_metrics = {'accuracy', 'recall', 'precision', 'F1-score', 'ROC-AUC'}\n",
    "model_metrics = {}\n",
    "\n",
    "# all of the models\n",
    "models = [best_cart, best_rf, best_lr, best_nb, best_knn, best_svmrbf, best_svmlin, best_svmsig, best_xgb, best_ada, ensemble]\n",
    "model_names = ['CART', 'RF', 'LR', 'GNB', 'kNN', 'SVM-RBF', 'SVM-Lin', 'SVM-Sig', 'XGB', 'ADA', 'Ensemble']\n",
    "i=0\n",
    "for model in models:\n",
    "    # train on test set\n",
    "    predicted = model.predict(testing_data)\n",
    "    # generate cm against test labels\n",
    "    cm = confusion_matrix(testing_labels, predicted)\n",
    "    # print(cm)\n",
    "    accuracy = accuracy_score(testing_labels, predicted)\n",
    "    recall = recall_score(testing_labels, predicted, average=None)\n",
    "    precision = precision_score(testing_labels, predicted, average=None)\n",
    "    f1 = f1_score(testing_labels, predicted, average=None)\n",
    "\n",
    "    try:\n",
    "        predicted_prob = model.predict_proba(testing_data)\n",
    "        roc = roc_auc_score(testing_labels, predicted_prob, average=None, multi_class='ovr') \n",
    "        # print(accuracy, recall, precision, f1, roc)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            },\n",
    "                                            'ROC-AUC':{\n",
    "                                                1:roc[0], \n",
    "                                                2:roc[1], \n",
    "                                                3:roc[2]\n",
    "                                            }\n",
    "        }\n",
    "    except:\n",
    "        print(f\"can't predict class probilities for {model_names[i]}\")\n",
    "        # print(accuracy, recall, precision, f1)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            }\n",
    "        }\n",
    "    i+=1\n",
    "\n",
    "# (Gern Blanston, 2009)- sort by neoplasia recall\n",
    "sorted_metrics = dict(sorted(model_metrics.items(), key=lambda item: item[1]['recall'][3], reverse=True))\n",
    "# (holys, 2013)\n",
    "with open(FILENAME_RECALL, 'w') as fp:\n",
    "    json.dump(sorted_metrics, fp)\n",
    "\n",
    "# redo but sort by accuracy\n",
    "# (Gern Blanston, 2009)\n",
    "sorted_metrics_acc = dict(sorted(model_metrics.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "# (holys, 2013)\n",
    "with open(FILENAME_ACC, 'w') as fp:\n",
    "    json.dump(sorted_metrics_acc, fp)\n",
    "model_metrics\n",
    "sorted_metrics\n",
    "FILENAME_ACC, FILENAME_RECALL\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_sorted_models (acc): \n",
      "dict_keys(['kNN', 'RF', 'XGB', 'SVM-RBF', 'CART', 'Ensemble', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n",
      "\n",
      "sorted models (acc): \n",
      "dict_keys(['Ensemble', 'RF', 'kNN', 'XGB', 'SVM-RBF', 'ADA', 'CART', 'LR', 'SVM-Lin', 'GNB', 'SVM-Sig'])\n",
      "\n",
      "sorted models (recall): \n",
      "dict_keys(['SVM-Sig', 'LR', 'GNB', 'kNN', 'SVM-RBF', 'XGB', 'Ensemble', 'RF', 'CART', 'ADA', 'SVM-Lin'])\n"
     ]
    }
   ],
   "source": [
    "# print highest acc models from gridsearch\n",
    "print(f\"gs_sorted_models (acc): \\n{gs_sorted_models.keys()}\\n\")\n",
    "\n",
    "# highest acc models from test set\n",
    "print(f\"sorted models (acc): \\n{sorted_metrics_acc.keys()}\\n\")\n",
    "\n",
    "# highest recall from test set\n",
    "print(f\"sorted models (recall): \\n{sorted_metrics.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.237762237762237 7.46551724137931 11\n",
      "4.881118881118881 3.8965517241379306 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': {'accuracy': 0.7488874761602033,\n",
       "  'neoplasia recall': 0.6786833855799372},\n",
       " 'top6': {'accuracy': 0.8135198135198135, 'recall': 0.6494252873563218}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Neekhara, 2019)\n",
    "import json\n",
    "DATASET = 'svmsmote'\n",
    "\n",
    "# function to add to JSON\n",
    "def write_json(new_data, filename='metrics/scoreboard.json'):\n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[DATASET] = (new_data)\n",
    "        file_data = dict(sorted(file_data.items(), key=lambda item: item[1]['all']['accuracy'], reverse=True))\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent = 4)\n",
    "\n",
    "# calculate avg accuracy and recall\n",
    "accuracy = 0\n",
    "recall = 0\n",
    "count = 0\n",
    "for model in model_names:\n",
    "    # print(model_metrics[model]['accuracy'])\n",
    "    accuracy += model_metrics[model]['accuracy']\n",
    "    recall += model_metrics[model]['recall'][3]\n",
    "    count +=1\n",
    "\n",
    "t6acc = 0\n",
    "t6rec = 0\n",
    "count2 = 0\n",
    "for key in sorted_metrics_acc:\n",
    "    if count2 ==6:\n",
    "        break\n",
    "    t6acc += sorted_metrics_acc[key]['accuracy']\n",
    "    t6rec += sorted_metrics_acc[key]['recall'][3]\n",
    "    count2 +=1\n",
    "\n",
    "avg = {'all' : {'accuracy': accuracy/count, 'neoplasia recall': recall/count},\n",
    "       'top6' : {'accuracy': t6acc/count2, 'recall':t6rec/count2}}\n",
    "print(accuracy, recall, count)\n",
    "print(t6acc, t6rec, count2)\n",
    "if DATASET != 'test':\n",
    "    write_json(avg)\n",
    "else:\n",
    "    print(DATASET)\n",
    "avg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observations on raw dataset\n",
    "XGBoost and ADAboost seem to have really overfit, because they severely underperform on unseen test data, compared to the accuracies they were achieving with gridsearch. IGNORE THIS: it is just because the test labels were not normalised!\n",
    "\n",
    "Although GNB has higher recall for neoplasia than kNN, kNN seems to be the best classifier overall. While GNB has highest recall for neoplasia, has 3rd lowest accuracy.\n",
    "\n",
    "Top models based on accuracy, from gridsearch, were RF, kNN, XGB, SVM-RBF, CART. Top models based on accuracy, from test set, were RF, kNN, SVM-RBF, CART, SVM-Lin. Therefore, RF, kNN, SVM-RBF, CART seem to perform well, in terms of accuracy, and don't seem to produce drastically different results with the test set, suggesting there isn't much overfitting\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'kNN', 'XGB', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'ADA', 'SVM-Sig', 'GNB'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'SVM-Lin', 'LR', 'SVM-Sig', 'GNB', 'ADA'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'kNN', 'CART', 'RF', 'SVM-Lin', 'XGB', 'LR', 'SVM-RBF', 'SVM-Sig', 'ADA'])\n",
    "\n",
    "# observations on feature selected dataset\n",
    "Some models decreased in performance, some increased, with largest increase being 6% increase in accuracy for SVM-Lin model. But overall, not worth, since the max accuracy of any of the models was lower than without feature selection. Maybe better feature selection is needed - an analytical solution rather than eyeball\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'SVM-RBF', 'kNN', 'XGB', 'CART', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'GNB', 'ADA', 'SVM-Sig'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'SVM-RBF', 'XGB', 'RF', 'kNN', 'SVM-Lin', 'CART', 'LR', 'SVM-Sig', 'ADA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69968d942e1dcc7d0770d34dbcb974701730c09224194d51fbd302d9296a213d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
