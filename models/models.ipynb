{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import os, json\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train\n",
    "training_data = pd.read_csv('../data/original_data/noExclusion_train_data.csv', header = None)\n",
    "# y_train\n",
    "training_labels = pd.read_csv('../data/original_data/noExclusion_train_label.csv', header = None)\n",
    "# x_test\n",
    "testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "# y_test\n",
    "testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type cast labels to ints\n",
    "# training_labels.columns\n",
    "# training_labels[0]\n",
    "training_labels[0] = training_labels[0].astype(int)\n",
    "testing_labels[0] = testing_labels[0].astype(int)\n",
    "# testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': None, 'max_features': 'log2'} \n",
      "best_score: 0.806019358741682\n"
     ]
    }
   ],
   "source": [
    "# make CART classifier\n",
    "clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "# find optimal parameter values for CART\n",
    "params = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30, 35, 40], # control overfitting,\n",
    "    'max_features': [None, 'sqrt', 'log2'] # performance \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_cart, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_cart = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': 10, 'max_features': 30, 'n_estimators': 50} \n",
      "best_score: 0.851482153660012\n"
     ]
    }
   ],
   "source": [
    "# make Random Forest classifier\n",
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "params = {\n",
    "  'n_estimators': [10, 50, 100, 200, 300],\n",
    "  'max_depth': [None, 5, 10, 20, 30, 40],\n",
    "  \"max_features\" : [None, 1, 5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# so it doesn't redo lengthy GS\n",
    "params = {\n",
    "  'n_estimators': [50],\n",
    "  'max_depth': [10],\n",
    "  \"max_features\" : [30]\n",
    "}\n",
    "\n",
    "grid_search  = GridSearchCV(clf_rf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "best_score: 0.7658197217180883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# make Logistic Regressor\n",
    "clf_lr = LogisticRegression(random_state=1)\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'], # type of regularisation \n",
    "    'C': [0.1, 1, 10, 100], # regularisation strength\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'] # approach to finding best weights\n",
    "}\n",
    "# so it doesn't redo lengthy GS\n",
    "params = {\n",
    "    'penalty': ['l2'], # type of regularisation \n",
    "    'C': [0.1], # regularisation strength\n",
    "    'solver': ['lbfgs'] # approach to finding best weights\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_lr, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "best_score: 0.7658197217180883\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_lr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'var_smoothing': 1e-15} \n",
      "best_score: 0.6347549909255898\n"
     ]
    }
   ],
   "source": [
    "# make Gaussian Naive Bayes classifier\n",
    "clf_nb = GaussianNB()\n",
    "params = {\n",
    "    'var_smoothing':[1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9], # from less smoothing to more aggressive smoothing\n",
    "}\n",
    "grid_search = GridSearchCV(clf_nb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_nb = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'n_neighbors': 1} \n",
      "best_score: 0.8496067755595886\n"
     ]
    }
   ],
   "source": [
    "# make k-Nearest Neighbours classifier\n",
    "clf_knn = KNeighborsClassifier(n_jobs=-1) # use all processes for parellelisation\n",
    "params = {\n",
    "    'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "}\n",
    "grid_search = GridSearchCV(clf_knn, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_knn = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'C': 100, 'gamma': 'scale'} \n",
      "best_score: 0.8357229280096792\n"
     ]
    }
   ],
   "source": [
    "# make SVM-RBF classifier\n",
    "clf_svmrbf = SVC(kernel='rbf', random_state=1)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "# so it doesn't redo lengthy GS\n",
    "params = {\n",
    "    'C': [100], # high to low regularisation strength\n",
    "    'gamma' : ['scale'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_svmrbf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmrbf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'C': 10, 'gamma': 'scale'} \n",
      "best_score: 0.7553539019963702\n"
     ]
    }
   ],
   "source": [
    "# make SVM linear classifier\n",
    "clf_lin = SVC(kernel='linear', random_state=1)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "grid_search = GridSearchCV(clf_lin, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmlin = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'C': 10, 'gamma': 'auto'} \n",
      "best_score: 0.6658802177858438\n"
     ]
    }
   ],
   "source": [
    "# make svm sigmoidal classifier\n",
    "clf_sig = SVC(kernel='sigmoid', random_state=1)\n",
    "params = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "grid_search = GridSearchCV(clf_sig, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmsig = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': 10, 'n_estimators': 100} \n",
      "best_score: 0.8463399879007865\n"
     ]
    }
   ],
   "source": [
    "# make xgboost classifier\n",
    "clf_xgb = xgb.XGBClassifier(random_state = 1)\n",
    "\n",
    "# encode labels, using sklearn, to pass to xgboost\n",
    "# this code was inspired by the snippet from:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "# fit the classes to the encoder and transform labels\n",
    "e_train_labels = le.fit_transform(training_labels[0].to_list())\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10,100, 500, 1000], # no. boosting rounds\n",
    "    'max_depth': [3,5,7,10,15] # control overfitting\n",
    "}\n",
    "\n",
    "# so it doesn't redo lengthy GS\n",
    "params = {\n",
    "    'n_estimators': [100], # no. boosting rounds\n",
    "    'max_depth': [10] # control overfitting\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_xgb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, e_train_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_xgb = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'learning_rate': 0.01, 'n_estimators': 50} \n",
      "best_score: 0.6696007259528131\n"
     ]
    }
   ],
   "source": [
    "# make adaboost classifier\n",
    "clf_ada = AdaBoostClassifier(random_state=1)\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100, 500, 1000],\n",
    "    'learning_rate': [0, 0.01, 0.1, 1, 10] # weight applied to each clf at each boosting iteration\n",
    "}\n",
    "\n",
    "# so it doesn't redo lengthy GS\n",
    "params = {\n",
    "    'n_estimators': [50],\n",
    "    'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_ada, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, e_train_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score}\")\n",
    "best_ada = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  0  2]\n",
      " [ 1 53  9]\n",
      " [ 2 18 38]]\n",
      "0.7762237762237763 [0.90909091 0.84126984 0.65517241] [0.86956522 0.74647887 0.7755102 ] [0.88888889 0.79104478 0.71028037] [0.94214876 0.80813492 0.76288032]\n",
      "[[20  2  0]\n",
      " [ 0 62  1]\n",
      " [ 1 19 38]]\n",
      "0.8391608391608392 [0.90909091 0.98412698 0.65517241] [0.95238095 0.74698795 0.97435897] [0.93023256 0.84931507 0.78350515] [0.99774606 0.94166667 0.93752535]\n",
      "[[21  1  0]\n",
      " [ 1 48 14]\n",
      " [ 2 21 35]]\n",
      "0.7272727272727273 [0.95454545 0.76190476 0.60344828] [0.875      0.68571429 0.71428571] [0.91304348 0.72180451 0.65420561] [0.99699474 0.83313492 0.82089249]\n",
      "[[22  0  0]\n",
      " [ 9 30 24]\n",
      " [ 3 13 42]]\n",
      "0.6573426573426573 [1.         0.47619048 0.72413793] [0.64705882 0.69767442 0.63636364] [0.78571429 0.56603774 0.67741935] [0.95041322 0.7593254  0.76064909]\n",
      "[[20  1  1]\n",
      " [ 1 56  6]\n",
      " [ 0 17 41]]\n",
      "0.8181818181818182 [0.90909091 0.88888889 0.70689655] [0.95238095 0.75675676 0.85416667] [0.93023256 0.81751825 0.77358491] [0.95041322 0.83194444 0.81227181]\n",
      "[[22  0  0]\n",
      " [ 0 62  1]\n",
      " [ 2 23 33]]\n",
      "can't predict class probilities for SVM-RBF\n",
      "0.8181818181818182 [1.         0.98412698 0.56896552] [0.91666667 0.72941176 0.97058824] [0.95652174 0.83783784 0.7173913 ]\n",
      "[[22  0  0]\n",
      " [ 0 50 13]\n",
      " [ 2 19 37]]\n",
      "can't predict class probilities for SVM-Lin\n",
      "0.7622377622377622 [1.         0.79365079 0.63793103] [0.91666667 0.72463768 0.74      ] [0.95652174 0.75757576 0.68518519]\n",
      "[[18  4  0]\n",
      " [ 1 52 10]\n",
      " [ 6 24 28]]\n",
      "can't predict class probilities for SVM-Sig\n",
      "0.6853146853146853 [0.81818182 0.82539683 0.48275862] [0.72       0.65       0.73684211] [0.76595745 0.72727273 0.58333333]\n",
      "[[ 0  0  0  0]\n",
      " [22  0  0  0]\n",
      " [ 0 61  2  0]\n",
      " [ 1 20 37  0]]\n",
      "0.013986013986013986 [0.         0.         0.03174603 0.        ] [0.         0.         0.05128205 0.        ] [0.         0.         0.03921569 0.        ] [0.99887303 0.92321429 0.90811359]\n",
      "[[ 0  0  0  0]\n",
      " [20  2  0  0]\n",
      " [ 0 63  0  0]\n",
      " [ 1 57  0  0]]\n",
      "0.013986013986013986 [0.         0.09090909 0.         0.        ] [0.         0.01639344 0.         0.        ] [0.         0.02777778 0.         0.        ] [0.99229902 0.79761905 0.78833671]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CART': {'accuracy': 0.7762237762237763,\n",
       "  'recall': {1: 0.9090909090909091,\n",
       "   2: 0.8412698412698413,\n",
       "   3: 0.6551724137931034},\n",
       "  'precision': {1: 0.8695652173913043,\n",
       "   2: 0.7464788732394366,\n",
       "   3: 0.7755102040816326},\n",
       "  'f1_score': {1: 0.888888888888889,\n",
       "   2: 0.791044776119403,\n",
       "   3: 0.7102803738317757},\n",
       "  'ROC-AUC': {1: 0.9421487603305786,\n",
       "   2: 0.8081349206349207,\n",
       "   3: 0.7628803245436105}},\n",
       " 'RF': {'accuracy': 0.8391608391608392,\n",
       "  'recall': {1: 0.9090909090909091,\n",
       "   2: 0.9841269841269841,\n",
       "   3: 0.6551724137931034},\n",
       "  'precision': {1: 0.9523809523809523,\n",
       "   2: 0.7469879518072289,\n",
       "   3: 0.9743589743589743},\n",
       "  'f1_score': {1: 0.9302325581395349,\n",
       "   2: 0.8493150684931506,\n",
       "   3: 0.7835051546391754},\n",
       "  'ROC-AUC': {1: 0.9977460555972953,\n",
       "   2: 0.9416666666666667,\n",
       "   3: 0.937525354969574}},\n",
       " 'LR': {'accuracy': 0.7272727272727273,\n",
       "  'recall': {1: 0.9545454545454546,\n",
       "   2: 0.7619047619047619,\n",
       "   3: 0.603448275862069},\n",
       "  'precision': {1: 0.875, 2: 0.6857142857142857, 3: 0.7142857142857143},\n",
       "  'f1_score': {1: 0.9130434782608695,\n",
       "   2: 0.7218045112781954,\n",
       "   3: 0.6542056074766354},\n",
       "  'ROC-AUC': {1: 0.9969947407963937,\n",
       "   2: 0.8331349206349206,\n",
       "   3: 0.8208924949290061}},\n",
       " 'GNB': {'accuracy': 0.6573426573426573,\n",
       "  'recall': {1: 1.0, 2: 0.47619047619047616, 3: 0.7241379310344828},\n",
       "  'precision': {1: 0.6470588235294118,\n",
       "   2: 0.6976744186046512,\n",
       "   3: 0.6363636363636364},\n",
       "  'f1_score': {1: 0.7857142857142858,\n",
       "   2: 0.5660377358490566,\n",
       "   3: 0.6774193548387097},\n",
       "  'ROC-AUC': {1: 0.9504132231404959,\n",
       "   2: 0.7593253968253968,\n",
       "   3: 0.7606490872210954}},\n",
       " 'kNN': {'accuracy': 0.8181818181818182,\n",
       "  'recall': {1: 0.9090909090909091,\n",
       "   2: 0.8888888888888888,\n",
       "   3: 0.7068965517241379},\n",
       "  'precision': {1: 0.9523809523809523,\n",
       "   2: 0.7567567567567568,\n",
       "   3: 0.8541666666666666},\n",
       "  'f1_score': {1: 0.9302325581395349,\n",
       "   2: 0.8175182481751826,\n",
       "   3: 0.7735849056603773},\n",
       "  'ROC-AUC': {1: 0.9504132231404959,\n",
       "   2: 0.8319444444444444,\n",
       "   3: 0.8122718052738336}},\n",
       " 'SVM-RBF': {'accuracy': 0.8181818181818182,\n",
       "  'recall': {1: 1.0, 2: 0.9841269841269841, 3: 0.5689655172413793},\n",
       "  'precision': {1: 0.9166666666666666,\n",
       "   2: 0.7294117647058823,\n",
       "   3: 0.9705882352941176},\n",
       "  'f1_score': {1: 0.9565217391304348,\n",
       "   2: 0.8378378378378377,\n",
       "   3: 0.717391304347826}},\n",
       " 'SVM-Lin': {'accuracy': 0.7622377622377622,\n",
       "  'recall': {1: 1.0, 2: 0.7936507936507936, 3: 0.6379310344827587},\n",
       "  'precision': {1: 0.9166666666666666, 2: 0.7246376811594203, 3: 0.74},\n",
       "  'f1_score': {1: 0.9565217391304348,\n",
       "   2: 0.7575757575757576,\n",
       "   3: 0.6851851851851852}},\n",
       " 'SVM-Sig': {'accuracy': 0.6853146853146853,\n",
       "  'recall': {1: 0.8181818181818182,\n",
       "   2: 0.8253968253968254,\n",
       "   3: 0.4827586206896552},\n",
       "  'precision': {1: 0.72, 2: 0.65, 3: 0.7368421052631579},\n",
       "  'f1_score': {1: 0.7659574468085107,\n",
       "   2: 0.7272727272727272,\n",
       "   3: 0.5833333333333334}},\n",
       " 'XGB': {'accuracy': 0.013986013986013986,\n",
       "  'recall': {1: 0.0, 2: 0.0, 3: 0.031746031746031744},\n",
       "  'precision': {1: 0.0, 2: 0.0, 3: 0.05128205128205128},\n",
       "  'f1_score': {1: 0.0, 2: 0.0, 3: 0.0392156862745098},\n",
       "  'ROC-AUC': {1: 0.9988730277986476,\n",
       "   2: 0.9232142857142857,\n",
       "   3: 0.9081135902636917}},\n",
       " 'ADA': {'accuracy': 0.013986013986013986,\n",
       "  'recall': {1: 0.0, 2: 0.09090909090909091, 3: 0.0},\n",
       "  'precision': {1: 0.0, 2: 0.01639344262295082, 3: 0.0},\n",
       "  'f1_score': {1: 0.0, 2: 0.02777777777777778, 3: 0.0},\n",
       "  'ROC-AUC': {1: 0.9922990232907588,\n",
       "   2: 0.7976190476190477,\n",
       "   3: 0.7883367139959432}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate models (Anon, 2023b)\n",
    "# model_metrics = {'accuracy', 'recall', 'precision', 'F1-score', 'ROC-AUC'}\n",
    "model_metrics = {}\n",
    "\n",
    "# all of the models\n",
    "models = [best_cart, best_rf, best_lr, best_nb, best_knn, best_svmrbf, best_svmlin, best_svmsig, best_xgb, best_ada]\n",
    "model_names = ['CART', 'RF', 'LR', 'GNB', 'kNN', 'SVM-RBF', 'SVM-Lin', 'SVM-Sig', 'XGB', 'ADA']\n",
    "i=0\n",
    "for model in models:\n",
    "    # train on test set\n",
    "    predicted = model.predict(testing_data)\n",
    "    # generate cm against test labels\n",
    "    cm = confusion_matrix(testing_labels, predicted)\n",
    "    print(cm)\n",
    "    accuracy = accuracy_score(testing_labels, predicted)\n",
    "    recall = recall_score(testing_labels, predicted, average=None)\n",
    "    precision = precision_score(testing_labels, predicted, average=None)\n",
    "    f1 = f1_score(testing_labels, predicted, average=None)\n",
    "\n",
    "    try:\n",
    "        predicted_prob = model.predict_proba(testing_data)\n",
    "        roc = roc_auc_score(testing_labels, predicted_prob, average=None, multi_class='ovr') \n",
    "        print(accuracy, recall, precision, f1, roc)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            },\n",
    "                                            'ROC-AUC':{\n",
    "                                                1:roc[0], \n",
    "                                                2:roc[1], \n",
    "                                                3:roc[2]\n",
    "                                            }\n",
    "        }\n",
    "    except:\n",
    "        print(f\"can't predict class probilities for {model_names[i]}\")\n",
    "        print(accuracy, recall, precision, f1)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            }\n",
    "        }\n",
    "    i+=1\n",
    "\n",
    "# (Gern Blanston, 2009)\n",
    "sorted_metrics = \n",
    "# (holys, 2013)\n",
    "with open('metrics/model_metrics.json', 'w') as fp:\n",
    "    json.dump(model_metrics, fp)\n",
    "model_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69968d942e1dcc7d0770d34dbcb974701730c09224194d51fbd302d9296a213d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
