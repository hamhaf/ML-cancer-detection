{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import os, json\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV, Optimizer\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snv_FS_my_balanced'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toggle option\n",
    "SNV = True\n",
    "FEATURE_SELECT = True\n",
    "FEATURE_SELECTv2 = False\n",
    "BALANCED = False\n",
    "MY_BALANCED = True\n",
    "TEST = False\n",
    "\n",
    "# Choose dataset\n",
    "DATASET = 'raw'\n",
    "FILENAME_ACC = 'metrics/raw_dataset/model_metrics_accuracy_ensemble.json'\n",
    "FILENAME_RECALL = 'metrics/raw_dataset/model_metrics_recall_ensemble.json'\n",
    "if TEST:\n",
    "    DATASET = 'test'\n",
    "    FILENAME_ACC = 'metrics/temp/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/temp/model_metrics_recall_ensemble.json'\n",
    "elif BALANCED:\n",
    "    DATASET = 'balanced'\n",
    "    FILENAME_ACC = 'metrics/balanced_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/balanced_dataset/model_metrics_recall_ensemble.json'\n",
    "    if SNV:\n",
    "        DATASET = 'snv_balanced'\n",
    "        FILENAME_ACC = 'metrics/balanced_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "        FILENAME_RECALL = 'metrics/balanced_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "elif MY_BALANCED:\n",
    "    DATASET = 'my_balanced'\n",
    "    FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble.json'\n",
    "    FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble.json'\n",
    "    if FEATURE_SELECT:\n",
    "        DATASET = 'FS_my_balanced'\n",
    "        FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_FS.json'\n",
    "        FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_FS.json'\n",
    "        if SNV:\n",
    "            DATASET = 'snv_FS_my_balanced'\n",
    "            FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv_FS.json'\n",
    "            FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_snv_FS.json'\n",
    "    elif FEATURE_SELECTv2:\n",
    "        DATASET = 'FSv2_my_balanced'\n",
    "        FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_FSv2.json'\n",
    "        FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_FSv2.json'\n",
    "    elif SNV:\n",
    "        DATASET = 'snv_my_balanced'\n",
    "        FILENAME_ACC = 'metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv.json'\n",
    "        FILENAME_RECALL = 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_snv.json'\n",
    "elif SNV:\n",
    "    DATASET = 'snv_raw'\n",
    "    FILENAME_ACC = 'metrics/raw_dataset/model_metrics_accuracy_snv.json'\n",
    "    FILENAME_RECALL = 'metrics/raw_dataset/model_metrics_recall_snv.json'\n",
    "elif FEATURE_SELECT:\n",
    "    DATASET = 'feature_select'\n",
    "    FILENAME_ACC = 'metrics/selected_features/model_metrics_accuracy.json'\n",
    "    FILENAME_RECALL = 'metrics/selected_features/model_metrics_recall.json'\n",
    "elif FEATURE_SELECTv2:\n",
    "    DATASET = 'feature_selectv2'\n",
    "    FILENAME_ACC = 'metrics/selected_features/model_metrics_accuracy2.json'\n",
    "    FILENAME_RECALL = 'metrics/selected_features/model_metrics_recall2.json'\n",
    "\n",
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MY_BALANCED:\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/balanced_data/train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/balanced_data/train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/balanced_data/test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/balanced_data/test_label.csv', header = None)\n",
    "elif BALANCED:\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/original_data/balanced_train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/original_data/balanced_train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/balanced_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/balanced_test_label.csv', header = None)\n",
    "else:\n",
    "    # x_train\n",
    "    training_data = pd.read_csv('../data/original_data/noExclusion_train_data.csv', header = None)\n",
    "    # y_train\n",
    "    training_labels = pd.read_csv('../data/original_data/noExclusion_train_label.csv', header = None)\n",
    "    # x_test\n",
    "    testing_data = pd.read_csv('../data/original_data/noExclusion_test_data.csv', header = None)\n",
    "    # y_test\n",
    "    testing_labels = pd.read_csv('../data/original_data/noExclusion_test_label.csv', header = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data: <class 'pandas.core.frame.DataFrame'>, \n",
      "training_labels: <class 'pandas.core.frame.DataFrame'>, \n",
      "testing_data: <class 'pandas.core.frame.DataFrame'>, \n",
      "testing_labels: <class 'pandas.core.frame.DataFrame'>\n",
      "training labels vc: \n",
      "2    177\n",
      "3    177\n",
      "1    119\n",
      "dtype: int64, \n",
      "testing labels vc: \n",
      "2    59\n",
      "3    59\n",
      "1    40\n",
      "dtype: int64\n",
      "473 473 158 158\n"
     ]
    }
   ],
   "source": [
    "print(f\"training_data: {type(training_data)}, \\ntraining_labels: {type(training_labels)}, \\ntesting_data: {type(testing_data)}, \\ntesting_labels: {type(testing_labels)}\")\n",
    "print(f\"training labels vc: \\n{training_labels.value_counts()}, \\ntesting labels vc: \\n{testing_labels.value_counts()}\")\n",
    "print(len(training_data), len(training_labels), len(testing_data), len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type cast labels to ints\n",
    "training_labels[0] = training_labels[0].astype(int)\n",
    "# testing_labels\n",
    "testing_labels[0] = testing_labels[0].astype(int)\n",
    "\n",
    "# encode labels, using sklearn, to pass to xgboost\n",
    "# this code was inspired by the snippet from:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "# fit the classes to the encoder and transform labels to be 0,1,2\n",
    "training_labels = le.fit_transform(training_labels[0].to_list())\n",
    "testing_labels = le.fit_transform(testing_labels[0].to_list())\n",
    "\n",
    "# gridsearch results\n",
    "gs_results = {}\n",
    "np.unique(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO APPLY FEATURE SELECTION TO TRAINING DATA\n",
    "if FEATURE_SELECT == True:\n",
    "    ADD_POSSIBLE_FIGURES = True\n",
    "\n",
    "    # figures contain features from (figure_num*4)+1 \n",
    "    selected_figures = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                        21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\n",
    "                        39,40,41,42,43,44,45,46,47,48,49,50,51,52]\n",
    "\n",
    "    # figures that MAY be decent - noisy but different peaks\n",
    "    possible_figures = [53,54,56,57,58,59,60,61,62,63,64,65]\n",
    "\n",
    "    # decent features - eyeballed\n",
    "\n",
    "    # generate set of selected features\n",
    "    selected_features = []\n",
    "\n",
    "    for figure_num in selected_figures:\n",
    "        for i in range(0,4):\n",
    "            # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "            selected_features.append((figure_num*4)+i)\n",
    "\n",
    "    # to add possible features\n",
    "    if ADD_POSSIBLE_FIGURES == True:\n",
    "        for figure_num in possible_figures:\n",
    "            for i in range(0,4):\n",
    "                # print(f\"figure: {figure_num}, feature: feature_{(figure_num*4)+i}\")\n",
    "                selected_features.append((figure_num*4)+i)\n",
    "                \n",
    "    training_data = training_data[selected_features]\n",
    "    testing_data = testing_data[selected_features]\n",
    "else:\n",
    "    print('no feature selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 260)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no FSv2\n"
     ]
    }
   ],
   "source": [
    "if FEATURE_SELECTv2:    \n",
    "    # selected features round 2\n",
    "    selected_features = []\n",
    "    a = np.arange(30,85).tolist()\n",
    "    b = np.arange(203,235).tolist()\n",
    "\n",
    "    selected_features = np.concatenate([a,b]).tolist()\n",
    "    print(selected_features)\n",
    "    # (Cena, 2018)\n",
    "    training_data = training_data[selected_features]\n",
    "    testing_data = testing_data[selected_features]\n",
    "else:\n",
    "    print('no FSv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n",
      "After: \n",
      " 473\n"
     ]
    }
   ],
   "source": [
    "# apply SNV to training data - inspired by code from my ML CW\n",
    "# (Hamzah Hafejee, 2022, COMP3611_Coursework_Assessment.ipynb, Comp 3611, University of Leeds)\n",
    "# (Sklearn, 2023)\n",
    "if SNV == True:\n",
    "    print(len(training_data))\n",
    "    # fit to training data\n",
    "    scaler = StandardScaler().fit(training_data)\n",
    "    training_data = scaler.transform(training_data)\n",
    "    testing_data = scaler.transform(testing_data)\n",
    "    print(\"After: \\n\", len(training_data))\n",
    "    len(training_data)\n",
    "else:\n",
    "    print('no SNV standardisation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snv_FS_my_balanced'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO USE AVG RECALL AS METRIC FOR GS\n",
    "# (gunes, 2019)\n",
    "gs_recall = make_scorer(recall_score, average='macro')\n",
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': 5, 'max_features': None} \n",
      "best_score: 0.777881205673759\n"
     ]
    }
   ],
   "source": [
    "# make CART classifier\n",
    "clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "# find optimal parameter values for CART\n",
    "params = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30, 35, 40], # control overfitting,\n",
    "    'max_features': [None, 'sqrt', 'log2'] # performance \n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'max_depth': [None], # control overfitting,\n",
    "        'max_features': ['log2'] # performance \n",
    "    }\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'max_depth': [5], # control overfitting,\n",
    "        'max_features': [None] # performance \n",
    "    }\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # feature select v2\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'max_depth': [None], 'max_features': ['log2']} \n",
    "elif DATASET == 'balanced':\n",
    "    params = {'max_depth': [10], 'max_features': ['sqrt']} \n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "    \n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': ['log2']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': ['sqrt']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [5], 'max_features': [None]} \n",
    "   \n",
    "grid_search = GridSearchCV(clf_cart, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_cart = grid_search.best_estimator_\n",
    "gs_results['CART'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Real(low=0, high=1, prior='uniform', transform='identity'),\n",
       " Categorical(categories=('a', 'b', 'c'), prior=None),\n",
       " Integer(low=0, high=1, prior='uniform', transform='identity')]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "space = [Real(0, 1, name='real'),\n",
    "            Categorical(['a', 'b', 'c'], name='cat'),\n",
    "            Integer(0, 1, name='int')]\n",
    "space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: Integer(\u001b[39m1\u001b[39m,\u001b[39m100\u001b[39m), \u001b[39m# control overfitting,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_features\u001b[39m\u001b[39m'\u001b[39m: Categorical([\u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39msqrt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlog2\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m# performance \u001b[39;00m\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m bayes_search \u001b[39m=\u001b[39m BayesSearchCV(clf_cart, params, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m _ \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39;49mfit(training_data, np\u001b[39m.\u001b[39;49mravel(training_labels))\n\u001b[0;32m     11\u001b[0m best_params \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m     12\u001b[0m best_score \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, groups\u001b[39m=\u001b[39mgroups, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[0;32m    513\u001b[0m         search_space, optimizer,\n\u001b[0;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[39m=\u001b[39;49mn_points_adjusted\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\searchcv.py:400\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m# get parameter values to evaluate\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m params \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mask(n_points\u001b[39m=\u001b[39;49mn_points)\n\u001b[0;32m    402\u001b[0m \u001b[39m# convert parameters to python native types\u001b[39;00m\n\u001b[0;32m    403\u001b[0m params \u001b[39m=\u001b[39m [[np\u001b[39m.\u001b[39marray(v)\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m p] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params]\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:395\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    393\u001b[0m X \u001b[39m=\u001b[39m []\n\u001b[0;32m    394\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_points):\n\u001b[1;32m--> 395\u001b[0m     x \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mask()\n\u001b[0;32m    396\u001b[0m     X\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m    398\u001b[0m     ti_available \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mps\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macq_func \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(opt\u001b[39m.\u001b[39myi) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:367\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Query point or multiple points at which objective should be evaluated.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[0;32m    338\u001b[0m \u001b[39mn_points : int or None, default: None\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \n\u001b[0;32m    365\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m n_points \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ask()\n\u001b[0;32m    369\u001b[0m supported_strategies \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcl_min\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcl_mean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcl_max\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(n_points, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m n_points \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:434\u001b[0m, in \u001b[0;36mOptimizer._ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_initial_points \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_estimator_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     \u001b[39m# this will not make a copy of `self.rng` and hence keep advancing\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[39m# our random state.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 434\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspace\u001b[39m.\u001b[39;49mrvs(random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrng)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    435\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m         \u001b[39m# The samples are evaluated starting form initial_samples[0]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_samples[\n\u001b[0;32m    438\u001b[0m             \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_samples) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_initial_points]\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\space\\space.py:900\u001b[0m, in \u001b[0;36mSpace.rvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    897\u001b[0m columns \u001b[39m=\u001b[39m []\n\u001b[0;32m    899\u001b[0m \u001b[39mfor\u001b[39;00m dim \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions:\n\u001b[1;32m--> 900\u001b[0m     columns\u001b[39m.\u001b[39mappend(dim\u001b[39m.\u001b[39;49mrvs(n_samples\u001b[39m=\u001b[39;49mn_samples, random_state\u001b[39m=\u001b[39;49mrng))\n\u001b[0;32m    902\u001b[0m \u001b[39m# Transpose\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[39mreturn\u001b[39;00m _transpose_list_array(columns)\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\space\\space.py:158\u001b[0m, in \u001b[0;36mDimension.rvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    156\u001b[0m rng \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m    157\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rvs\u001b[39m.\u001b[39mrvs(size\u001b[39m=\u001b[39mn_samples, random_state\u001b[39m=\u001b[39mrng)\n\u001b[1;32m--> 158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minverse_transform(samples)\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\space\\space.py:528\u001b[0m, in \u001b[0;36mInteger.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[39m   original space.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39m# The concatenation of all transformed dimensions makes Xt to be\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m# of type float, hence the required cast back to int.\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m inv_transform \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Integer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49minverse_transform(Xt)\n\u001b[0;32m    529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inv_transform, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    530\u001b[0m     inv_transform \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(inv_transform)\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\space\\space.py:168\u001b[0m, in \u001b[0;36mDimension.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_transform\u001b[39m(\u001b[39mself\u001b[39m, Xt):\n\u001b[0;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m       original space.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49minverse_transform(Xt)\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\space\\transformers.py:309\u001b[0m, in \u001b[0;36mPipeline.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_transform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    308\u001b[0m     \u001b[39mfor\u001b[39;00m transformer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 309\u001b[0m         X \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49minverse_transform(X)\n\u001b[0;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\skopt\\space\\transformers.py:275\u001b[0m, in \u001b[0;36mNormalize.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    273\u001b[0m X_orig \u001b[39m=\u001b[39m X \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhigh \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow\n\u001b[0;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_int:\n\u001b[1;32m--> 275\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mround(X_orig)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39;49mint)\n\u001b[0;32m    276\u001b[0m \u001b[39mreturn\u001b[39;00m X_orig\n",
      "File \u001b[1;32mc:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# bayes search experiment (Skopt, 2017)\n",
    "clf_cart = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "# find optimal parameter values for CART\n",
    "params = {\n",
    "    'max_depth': Integer(1,100), # control overfitting,\n",
    "    'max_features': Categorical([None, 'sqrt', 'log2']) # performance \n",
    "}\n",
    "   \n",
    "bayes_search = BayesSearchCV(clf_cart, params, scoring='accuracy', cv=10)\n",
    "_ = bayes_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = bayes_search.best_params_\n",
    "best_score = bayes_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_cart = bayes_search.best_estimator_\n",
    "gs_results['CART'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 1, 'penalty': 'l2', 'solver': 'saga'} \n",
      "best_score: 0.7395833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sc19mhh\\Desktop\\Hamzah\\Uni\\CompSci\\ThirdYear\\FYP\\MyCode\\ML-cancer-detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# make Logistic Regressor\n",
    "clf_lr = LogisticRegression(random_state=1, max_iter=1000)\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'], # type of regularisation \n",
    "    'C': [0.1, 1, 10, 100], # regularisation strength\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'] # approach to finding best weights\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'penalty': ['l2'], # type of regularisation \n",
    "        'C': [0.1], # regularisation strength\n",
    "        'solver': ['lbfgs'] # approach to finding best weights\n",
    "    }\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'penalty': ['l2'], # type of regularisation \n",
    "        'C': [0.1], # regularisation strength\n",
    "        'solver': ['newton-cg'] # approach to finding best weights\n",
    "    }\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {'C': [1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [0.1], 'penalty': ['l2'], 'solver': ['lbfgs']} \n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [100], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [0.1], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [10], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [1], 'penalty': ['l1'], 'solver': ['saga']} \n",
    "    \n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [1], 'penalty': ['l2'], 'solver': ['saga']} \n",
    "    \n",
    "grid_search = GridSearchCV(clf_lr, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "gs_results['LR'] = {'accuracy':best_score, 'params':best_params}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 1, 'penalty': 'l2', 'solver': 'saga'} \n",
      "best_score: 0.7395833333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_lr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'var_smoothing': 1e-20} \n",
      "best_score: 0.6406028368794325\n"
     ]
    }
   ],
   "source": [
    "# make Gaussian Naive Bayes classifier\n",
    "clf_nb = GaussianNB()\n",
    "params = {\n",
    "    'var_smoothing':[1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9], # from less smoothing to more aggressive smoothing\n",
    "}\n",
    "grid_search = GridSearchCV(clf_nb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_nb = grid_search.best_estimator_\n",
    "gs_results['GNB'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'n_neighbors': 6} \n",
      "best_score: 0.8096631205673759\n"
     ]
    }
   ],
   "source": [
    "# make k-Nearest Neighbours classifier\n",
    "clf_knn = KNeighborsClassifier(n_jobs=-1) # use all processes for parellelisation\n",
    "params = {\n",
    "    'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "}\n",
    "grid_search = GridSearchCV(clf_knn, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_knn = grid_search.best_estimator_\n",
    "gs_results['kNN'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 5000, 'gamma': 'scale'} \n",
      "best_score: 0.8561613475177305\n"
     ]
    }
   ],
   "source": [
    "# make SVM-RBF classifier\n",
    "clf_svmrbf = SVC(kernel='rbf', random_state=1)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000, 5000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'C': [100], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'C': [1000], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # selected + possible features v2\n",
    "    params = {\n",
    "        'C': [1000], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [1000], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [1000], 'gamma': ['scale']}\n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [100], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [100], 'gamma':[ 'scale']} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [5000], 'gamma':[ 'scale']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [100], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [5000], 'gamma':[ 'scale']} \n",
    "    \n",
    "grid_search = GridSearchCV(clf_svmrbf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmrbf = grid_search.best_estimator_\n",
    "gs_results['SVM-RBF'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 0.1, 'gamma': 'scale'} \n",
      "best_score: 0.7458333333333333\n"
     ]
    }
   ],
   "source": [
    "# make SVM linear classifier\n",
    "clf_lin = SVC(kernel='linear', random_state=1)\n",
    "params = {\n",
    "    'C': [0.05, 0.1, 1, 10, 100, 1000], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'C': [10], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'C': [1], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'C': [1], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [1000], 'gamma':[ 'scale']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [0.05], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "    \n",
    "grid_search = GridSearchCV(clf_lin, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmlin = grid_search.best_estimator_\n",
    "gs_results['SVM-Lin'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'C': 0.1, 'gamma': 'scale'} \n",
      "best_score: 0.6131205673758865\n"
     ]
    }
   ],
   "source": [
    "# make svm sigmoidal classifier\n",
    "clf_sig = SVC(kernel='sigmoid', random_state=1)\n",
    "params = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100], # high to low regularisation strength\n",
    "    'gamma' : ['scale', 'auto'], # need to research this parameter more\n",
    "    # 'gamma' : [], # need to research this parameter more\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'C': [10], # high to low regularisation strength\n",
    "        'gamma' : ['auto'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'C': [1e-05], # high to low regularisation strength\n",
    "        'gamma' : ['scale'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'C': [0.1], # high to low regularisation strength\n",
    "        'gamma' : ['auto'], # need to research this parameter more\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['auto']}\n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "    \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'C': [10], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'C': [1], 'gamma':[ 'auto']} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['auto']} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'C': [0.1], 'gamma': ['scale']} \n",
    "    \n",
    "grid_search = GridSearchCV(clf_sig, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_svmsig = grid_search.best_estimator_\n",
    "gs_results['SVM-Sig'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': 10, 'n_estimators': 100} \n",
      "best_score: 0.8076241134751774\n"
     ]
    }
   ],
   "source": [
    "# make xgboost classifier (Piotr Poski, 2021)\n",
    "clf_xgb = xgb.XGBClassifier(random_state = 1)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10,100, 500, 1000], # no. boosting rounds\n",
    "    'max_depth': [3,5,7,10,15,20] # control overfitting\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'n_estimators': [100], # no. boosting rounds\n",
    "        'max_depth': [10] # control overfitting\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'n_estimators': [10], # no. boosting rounds\n",
    "        'max_depth': [5] # control overfitting\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'n_estimators': [100], # no. boosting rounds\n",
    "        'max_depth': [5] # control overfitting\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'max_depth': [10], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "    \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [500]} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'max_depth': [15], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [10], 'n_estimators': [100]} \n",
    "    \n",
    "grid_search = GridSearchCV(clf_xgb, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, training_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_xgb = grid_search.best_estimator_\n",
    "gs_results['XGB'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'learning_rate': 0.001, 'n_estimators': 1000} \n",
      "best_score: 0.7083333333333333\n"
     ]
    }
   ],
   "source": [
    "# make adaboost classifier\n",
    "clf_ada = AdaBoostClassifier(random_state=1)\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100, 500, 1000],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1, 10] # weight applied to each clf at each boosting iteration\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "    # raw dataset\n",
    "    params = {\n",
    "        'n_estimators': [50],\n",
    "        'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "    # selected + possible features\n",
    "    params = {\n",
    "        'n_estimators': [10],\n",
    "        'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "    # FSv2\n",
    "    params = {\n",
    "        'n_estimators': [50],\n",
    "        'learning_rate': [0.01] # weight applied to each clf at each boosting iteration\n",
    "    }\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "    # SNV + raw\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [10]} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [10]} \n",
    "    \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'learning_rate': [0.01], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'learning_rate': [0.1], 'n_estimators': [10]} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'learning_rate': [0.001], 'n_estimators': [1000]} \n",
    "    \n",
    "grid_search = GridSearchCV(clf_ada, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, training_labels)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_ada = grid_search.best_estimator_\n",
    "gs_results['ADA'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'max_depth': None, 'max_features': 10, 'n_estimators': 10} \n",
      "best_score: 0.8222960992907801\n"
     ]
    }
   ],
   "source": [
    "# make Random Forest classifier\n",
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "params = {\n",
    "  'n_estimators': [10, 50, 100, 200, 300],\n",
    "  'max_depth': [None, 5, 10, 20, 30, 40],\n",
    "  \"max_features\" : [None, 1, 5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "if DATASET == 'raw':\n",
    "  # raw dataset\n",
    "  params = {\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [10],\n",
    "    \"max_features\" : [30]\n",
    "  }\n",
    "\n",
    "elif DATASET == 'feature_select':\n",
    "  # selected + possible features\n",
    "  params = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [None],\n",
    "    \"max_features\" : [5]\n",
    "  }\n",
    "\n",
    "elif DATASET == 'feature_selectv2':\n",
    "  # feature select v2\n",
    "  params = {'max_depth': [None], 'max_features': [5], 'n_estimators': [300]}\n",
    "\n",
    "elif DATASET == 'snv_raw':\n",
    "  # SNV + raw\n",
    "  params = {'max_depth': [10], 'max_features': [30], 'n_estimators': [50]} \n",
    "\n",
    "elif DATASET == 'balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [100]} \n",
    "\n",
    "elif DATASET == 'snv_balanced':\n",
    "  params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [100]} \n",
    "  \n",
    "elif DATASET == 'my_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [300]} \n",
    "\n",
    "elif DATASET == 'FS_my_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [300]} \n",
    "\n",
    "elif DATASET == 'FSv2_my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': [30], 'n_estimators': [100]} \n",
    "    \n",
    "elif DATASET == 'snv_my_balanced':\n",
    "    params = {'max_depth': [10], 'max_features': [5], 'n_estimators': [300]}\n",
    "\n",
    "elif DATASET == 'snv_FS_my_balanced':\n",
    "    params = {'max_depth': [None], 'max_features': [10], 'n_estimators': [10]} \n",
    "\n",
    "grid_search  = GridSearchCV(clf_rf, params, scoring='accuracy', cv=10)\n",
    "grid_search.fit(training_data, np.ravel(training_labels))\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"params = {best_params} \\nbest_score: {best_score}\")\n",
    "best_rf = grid_search.best_estimator_\n",
    "gs_results['RF'] = {'accuracy':best_score, 'params':best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8544303797468354"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble model (Sklearn, 2014), (Sklearn, 2023)\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf), \n",
    "    ('knn', best_knn), \n",
    "    ('xgb', best_xgb), \n",
    "    ('svmrbf', best_svmrbf), \n",
    "    ('nb', best_nb)],\n",
    "    voting='hard',\n",
    "    n_jobs=-1)\n",
    "\n",
    "ensemble.fit(training_data, training_labels)\n",
    "\n",
    "accuracy = ensemble.score(testing_data, testing_labels)\n",
    "predictions = ensemble.transform(testing_data)\n",
    "gs_results['Ensemble'] = {'accuracy':accuracy}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CART': {'accuracy': 0.777881205673759, 'params': {'max_depth': 5, 'max_features': None}}, 'LR': {'accuracy': 0.7395833333333333, 'params': {'C': 1, 'penalty': 'l2', 'solver': 'saga'}}, 'GNB': {'accuracy': 0.6406028368794325, 'params': {'var_smoothing': 1e-20}}, 'kNN': {'accuracy': 0.8096631205673759, 'params': {'n_neighbors': 6}}, 'SVM-RBF': {'accuracy': 0.8561613475177305, 'params': {'C': 5000, 'gamma': 'scale'}}, 'SVM-Lin': {'accuracy': 0.7458333333333333, 'params': {'C': 0.1, 'gamma': 'scale'}}, 'SVM-Sig': {'accuracy': 0.6131205673758865, 'params': {'C': 0.1, 'gamma': 'scale'}}, 'XGB': {'accuracy': 0.8076241134751774, 'params': {'max_depth': 10, 'n_estimators': 100}}, 'ADA': {'accuracy': 0.7083333333333333, 'params': {'learning_rate': 0.001, 'n_estimators': 1000}}, 'RF': {'accuracy': 0.8222960992907801, 'params': {'max_depth': None, 'max_features': 10, 'n_estimators': 10}}, 'Ensemble': {'accuracy': 0.8544303797468354}}\n",
      "dict_keys(['SVM-RBF', 'Ensemble', 'RF', 'kNN', 'XGB', 'CART', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n"
     ]
    }
   ],
   "source": [
    "# sorted GS models\n",
    "print(gs_results)\n",
    "gs_sorted_models = dict(sorted(gs_results.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "print(gs_sorted_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't predict class probilities for SVM-RBF\n",
      "can't predict class probilities for SVM-Lin\n",
      "can't predict class probilities for SVM-Sig\n",
      "can't predict class probilities for Ensemble\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('metrics/my_balanced_dataset/model_metrics_accuracy_ensemble_snv_FS.json',\n",
       " 'metrics/my_balanced_dataset/model_metrics_recall_ensemble_snv_FS.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate models (Sklearn, 2023)\n",
    "# model_metrics = {'accuracy', 'recall', 'precision', 'F1-score', 'ROC-AUC'}\n",
    "model_metrics = {}\n",
    "\n",
    "# all of the models\n",
    "models = [best_cart, best_rf, best_lr, best_nb, best_knn, best_svmrbf, best_svmlin, best_svmsig, best_xgb, best_ada, ensemble]\n",
    "model_names = ['CART', 'RF', 'LR', 'GNB', 'kNN', 'SVM-RBF', 'SVM-Lin', 'SVM-Sig', 'XGB', 'ADA', 'Ensemble']\n",
    "i=0\n",
    "for model in models:\n",
    "    # train on test set\n",
    "    predicted = model.predict(testing_data)\n",
    "    # generate cm against test labels\n",
    "    cm = confusion_matrix(testing_labels, predicted)\n",
    "    # print(cm)\n",
    "    accuracy = accuracy_score(testing_labels, predicted)\n",
    "    recall = recall_score(testing_labels, predicted, average=None)\n",
    "    precision = precision_score(testing_labels, predicted, average=None)\n",
    "    f1 = f1_score(testing_labels, predicted, average=None)\n",
    "\n",
    "    try:\n",
    "        predicted_prob = model.predict_proba(testing_data)\n",
    "        roc = roc_auc_score(testing_labels, predicted_prob, average=None, multi_class='ovr') \n",
    "        # print(accuracy, recall, precision, f1, roc)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            },\n",
    "                                            'ROC-AUC':{\n",
    "                                                1:roc[0], \n",
    "                                                2:roc[1], \n",
    "                                                3:roc[2]\n",
    "                                            }\n",
    "        }\n",
    "    except:\n",
    "        print(f\"can't predict class probilities for {model_names[i]}\")\n",
    "        # print(accuracy, recall, precision, f1)\n",
    "        model_metrics[model_names[i]] = {\n",
    "                                            'accuracy':accuracy, \n",
    "                                            'recall':{\n",
    "                                                1:recall[0], \n",
    "                                                2:recall[1], \n",
    "                                                3:recall[2]\n",
    "                                            },\n",
    "                                            'precision':{\n",
    "                                                1:precision[0], \n",
    "                                                2:precision[1], \n",
    "                                                3:precision[2]\n",
    "                                            },\n",
    "                                            'f1_score':{\n",
    "                                                1:f1[0], \n",
    "                                                2:f1[1], \n",
    "                                                3:f1[2]\n",
    "                                            }\n",
    "        }\n",
    "    i+=1\n",
    "\n",
    "# (Gern Blanston, 2009)- sort by neoplasia recall\n",
    "sorted_metrics = dict(sorted(model_metrics.items(), key=lambda item: item[1]['recall'][3], reverse=True))\n",
    "# (holys, 2013)\n",
    "with open(FILENAME_RECALL, 'w') as fp:\n",
    "    json.dump(sorted_metrics, fp)\n",
    "\n",
    "# redo but sort by accuracy\n",
    "# (Gern Blanston, 2009)\n",
    "sorted_metrics_acc = dict(sorted(model_metrics.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
    "# (holys, 2013)\n",
    "with open(FILENAME_ACC, 'w') as fp:\n",
    "    json.dump(sorted_metrics_acc, fp)\n",
    "model_metrics\n",
    "sorted_metrics\n",
    "FILENAME_ACC, FILENAME_RECALL\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_sorted_models (acc): \n",
      "dict_keys(['SVM-RBF', 'Ensemble', 'RF', 'kNN', 'XGB', 'CART', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n",
      "\n",
      "sorted models (acc): \n",
      "dict_keys(['RF', 'SVM-RBF', 'XGB', 'kNN', 'Ensemble', 'CART', 'ADA', 'LR', 'SVM-Lin', 'GNB', 'SVM-Sig'])\n",
      "\n",
      "sorted models (recall): \n",
      "dict_keys(['RF', 'SVM-RBF', 'XGB', 'Ensemble', 'CART', 'kNN', 'GNB', 'SVM-Lin', 'SVM-Sig', 'LR', 'ADA'])\n"
     ]
    }
   ],
   "source": [
    "# print highest acc models from gridsearch\n",
    "print(f\"gs_sorted_models (acc): \\n{gs_sorted_models.keys()}\\n\")\n",
    "\n",
    "# highest acc models from test set\n",
    "print(f\"sorted models (acc): \\n{sorted_metrics_acc.keys()}\\n\")\n",
    "\n",
    "# highest recall from test set\n",
    "print(f\"sorted models (recall): \\n{sorted_metrics.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.772151898734178 8.220338983050846 11\n",
      "5.170886075949367 4.711864406779662 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': {'accuracy': 0.7974683544303798,\n",
       "  'neoplasia recall': 0.7473035439137132},\n",
       " 'top6': {'accuracy': 0.8618143459915611, 'recall': 0.7853107344632769}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Neekhara, 2019)\n",
    "import json\n",
    "# function to add to JSON\n",
    "def write_json(new_data, filename='metrics/scoreboard.json'):\n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[DATASET] = (new_data)\n",
    "        file_data = dict(sorted(file_data.items(), key=lambda item: item[1]['all']['accuracy'], reverse=True))\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent = 4)\n",
    "DATASET = 'snv_FS_my_balanced'\n",
    "\n",
    "# calculate avg accuracy and recall\n",
    "accuracy = 0\n",
    "recall = 0\n",
    "count = 0\n",
    "for model in model_names:\n",
    "    # print(model_metrics[model]['accuracy'])\n",
    "    accuracy += model_metrics[model]['accuracy']\n",
    "    recall += model_metrics[model]['recall'][3]\n",
    "    count +=1\n",
    "\n",
    "t6acc = 0\n",
    "t6rec = 0\n",
    "count2 = 0\n",
    "for key in sorted_metrics_acc:\n",
    "    if count2 ==6:\n",
    "        break\n",
    "    t6acc += sorted_metrics_acc[key]['accuracy']\n",
    "    t6rec += sorted_metrics_acc[key]['recall'][3]\n",
    "    count2 +=1\n",
    "\n",
    "avg = {'all' : {'accuracy': accuracy/count, 'neoplasia recall': recall/count},\n",
    "       'top6' : {'accuracy': t6acc/count2, 'recall':t6rec/count2}}\n",
    "print(accuracy, recall, count)\n",
    "print(t6acc, t6rec, count2)\n",
    "if DATASET != 'test':\n",
    "    write_json(avg)\n",
    "else:\n",
    "    print(DATASET)\n",
    "avg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observations on raw dataset\n",
    "XGBoost and ADAboost seem to have really overfit, because they severely underperform on unseen test data, compared to the accuracies they were achieving with gridsearch. IGNORE THIS: it is just because the test labels were not normalised!\n",
    "\n",
    "Although GNB has higher recall for neoplasia than kNN, kNN seems to be the best classifier overall. While GNB has highest recall for neoplasia, has 3rd lowest accuracy.\n",
    "\n",
    "Top models based on accuracy, from gridsearch, were RF, kNN, XGB, SVM-RBF, CART. Top models based on accuracy, from test set, were RF, kNN, SVM-RBF, CART, SVM-Lin. Therefore, RF, kNN, SVM-RBF, CART seem to perform well, in terms of accuracy, and don't seem to produce drastically different results with the test set, suggesting there isn't much overfitting\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'kNN', 'XGB', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'ADA', 'SVM-Sig', 'GNB'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'SVM-Lin', 'LR', 'SVM-Sig', 'GNB', 'ADA'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'kNN', 'CART', 'RF', 'SVM-Lin', 'XGB', 'LR', 'SVM-RBF', 'SVM-Sig', 'ADA'])\n",
    "\n",
    "# observations on feature selected dataset\n",
    "Some models decreased in performance, some increased, with largest increase being 6% increase in accuracy for SVM-Lin model. But overall, not worth, since the max accuracy of any of the models was lower than without feature selection. Maybe better feature selection is needed - an analytical solution rather than eyeball\n",
    "\n",
    "gs_sorted_models (acc): \n",
    "(['RF', 'SVM-RBF', 'kNN', 'XGB', 'CART', 'SVM-Lin', 'LR', 'ADA', 'GNB', 'SVM-Sig'])\n",
    "\n",
    "sorted models (acc): \n",
    "(['RF', 'XGB', 'kNN', 'SVM-RBF', 'CART', 'LR', 'SVM-Lin', 'GNB', 'ADA', 'SVM-Sig'])\n",
    "\n",
    "sorted models (recall): \n",
    "(['GNB', 'SVM-RBF', 'XGB', 'RF', 'kNN', 'SVM-Lin', 'CART', 'LR', 'SVM-Sig', 'ADA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69968d942e1dcc7d0770d34dbcb974701730c09224194d51fbd302d9296a213d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
